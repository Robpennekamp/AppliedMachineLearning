{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6GgydedI6kRr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n",
      "1500000\n",
      "2000000\n",
      "2500000\n",
      "3000000\n",
      "3500000\n",
      "4000000\n",
      "4500000\n",
      "4925535\n"
     ]
    }
   ],
   "source": [
    "import math, datetime, time, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import re\n",
    "\n",
    "\n",
    "def load_data(data_path):\n",
    "  data = pd.read_csv(data_path)  \n",
    "  return data\n",
    "\n",
    "inbound = load_data(\"inbound_loads.csv\")\n",
    "outbound = load_data(\"outbound_laods.csv\")\n",
    "weather = load_data(\"weather.csv\")\n",
    "#For loop to ensure that all pallet data is in the same dataframe\n",
    "pallet = load_data(\"Pallet_history_Gold_Spike[0].csv\")\n",
    "for x in range(1, 10):\n",
    "    pallet = pd.concat([pallet, load_data(f\"Pallet_history_Gold_Spike[{x}].csv\")])\n",
    "    print(len(pallet))\n",
    "trainentest = load_data(\"demand_kWtrain_val.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pwIsOHLEjdRk"
   },
   "outputs": [],
   "source": [
    "import math, datetime, time, random\n",
    "# for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "#import missingno #doesn't work, why?!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### function to add time columns to a dataframe\n",
    "\n",
    "def addtimecol(df, colname): ####input df and colname \n",
    "        df[colname] = pd.to_datetime(df[colname])         \n",
    "        df['year'] = df[colname].dt.year\n",
    "        df['month'] = df[colname].dt.month\n",
    "        df['day'] = df[colname].dt.day\n",
    "        df['hour'] = df[colname].dt.hour\n",
    "        df['minute'] = df[colname].dt.minute        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([    8,     9,    10,    11,    12,    13,    14,    15,    18,\n",
      "               23,\n",
      "            ...\n",
      "            38864, 38865, 40462, 42264, 43238, 44801, 51019, 51114, 51666,\n",
      "            51886],\n",
      "           dtype='int64', length=1996)\n"
     ]
    }
   ],
   "source": [
    "###preprocessing inbound dataframe\n",
    "#droplevels where carriercode is cancel or None because then you cannot estimate the temp. //its not that many\n",
    "#droplevels where load_start and truck_signin are both missing because useless info then\n",
    "inbound = load_data(\"inbound_loads.csv\")\n",
    "inbound_indexes = inbound[inbound['carrier_code'] == \"CANCEL\"].index\n",
    "print(inbound_indexes)\n",
    "inbound.drop(inbound_indexes, inplace = True)\n",
    "inbound.dropna(subset = ['customer_code'], inplace = True)\n",
    "inbound.dropna(axis = 0, how = 'any', thresh = 1, subset = ['load_start_datetime', 'truck_signin_datetime'], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-00cf07b74dcd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "####testing what pallet data says what\n",
    "\n",
    "###move_category each has their own unique work_types. There is no crossover between them.Inbound moves can be un-load, \n",
    "testpal = pd.DataFrame({'from_location_code' : pallet['from_location_code'], 'move_category' : pallet['move_category'], 'received_date' : pallet['received_date'], 'customer_code' : pallet['customer_code'],  'to_location_code' : pallet['to_location_code'],  'work_type' : pallet['work_type'],  'transaction_date' : pallet['transaction_date']    })\n",
    "\n",
    "outb = testpal[testpal['move_category'] == 'outbound move']\n",
    "inb = testpal[testpal['move_category'] == 'inbound move']\n",
    "loc = testpal[testpal['move_category'] == 'location move']\n",
    "movout = outb['work_type'].unique()\n",
    "movin = inb['work_type'].value_counts()\n",
    "movloc = loc['work_type'].unique()\n",
    "#print('moveout:     ', movout)\n",
    "#print('movin:     ', movin)\n",
    "#print('movloc:     ', movloc)\n",
    "\n",
    "### inbound move can be PUTAWAYS, UN-LOAD and INBOUNDRUN. What does each mean, does one mean that it is coming from the dock? \n",
    "inunl = testpal[testpal['work_type'] == 'UN-LOAD'] ##orders mainly coming from going to DR0.. and going to DR0... \n",
    "inputa = testpal[testpal['work_type'] == 'PUTAWAYS'] ##orders mainly coming from door numbers, and going to 0... number\n",
    "ininb = testpal[testpal['work_type'] == 'INBOUNDRUN'] ##orders mainly coming from DR0.., and going to large variety of places, inverter, dr.., \n",
    "#print('inunl:     ', inunl['to_location_code'].value_counts())\n",
    "#print('inputa:     ', inputa['to_location_code'].value_counts())\n",
    "#print('ininb:     ', ininb['to_location_code'].value_counts())\n",
    "\n",
    "####what is interesting data for where warm orders go.\n",
    "        ###move_category: outbound_move = not interesting because orders have already been stored(time between receive date and t is big)\n",
    "            #inbound_move = ; location_move = \n",
    "        ###received_date: skip too old packages because they are in the right temp. to store --> too old = longer than 72h. in?\n",
    "        ###to_location_code: CPsth = per definitie een outbound move. DRsth = per definitie een outbound move\n",
    "        ###work_type; MOVE = location_move; PUTAWAYs = inbound, close to entrance; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Iks72d6PMdey"
   },
   "outputs": [],
   "source": [
    "#### feature: how many warm/new products are in? at time t\n",
    "#I didn't include the estimate for temperature\n",
    "\n",
    "def f_warmproducts(time):                             ##from a single value in trainentest, get the amount of products that \n",
    "                                                      ###entered the building within 24 hours\n",
    "    amount = 0    \n",
    "    delta = timedelta(days = 1)    \n",
    "    t = datetime.datetime.strptime(time, '%m/%d/%y %H:%M')\n",
    "    newtime = delta + t\n",
    "    inbound['load_start_datetime'] = pd.to_datetime(inbound['load_start_datetime'])  ###make column datetime objects\n",
    "    \n",
    "    for index, row in inbound.iterrows():                                      ### amount+1 for each order that entered the building within 24h\n",
    "        if inbound.at[index, 'carrier_code'] != \"CANCEL\":\n",
    "            if t <= inbound.at[index, 'load_start_datetime'] <= newtime :\n",
    "                amount += measurewarmth(index, row)                            ### use measurewarmth to estimate the warmth that an entry brings in\n",
    "                \n",
    "    return amount\n",
    "                \n",
    "\n",
    "\n",
    "def measurewarmth(index, row):                                                ###currently, measure warmth uses the weight only to estimate the heat\n",
    "    weight = inbound.at[index, 'net_weight']\n",
    "    #medianwarmth(index,row) = \n",
    "    return weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####using the functions I made\n",
    "\n",
    "featurestrain = pd.DataFrame({'datetime_local': trainentest['datetime_local'][0:273987]})   ###making a dataframe for features\n",
    "featurestest = pd.DataFrame({'datetime_local': trainentest['datetime_local'][273988:]})\n",
    "for index, rows in featurestrain.iterrows(): ###This takes extremely long\n",
    "   \n",
    "    featurestrain['f_warmproducts'] = f_warmproducts(featurestrain.at[index, 'datetime_local'])\n",
    "    \n",
    "print(features)\n",
    "    \n",
    "\n",
    "\n",
    "###using addtimecol to inbound given a certain column\n",
    "#inbound = addtimecol(inbound, 'load_start_datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2537.0': 1.0,\n",
       " '8873.0': 0.0,\n",
       " '14104.0': -1.5,\n",
       " '625.0': 0.0,\n",
       " '8187.0': -1.0,\n",
       " '5810.0': -1.0,\n",
       " '6134.0': -2.0,\n",
       " '6910.0': -1.0,\n",
       " '899.0': 1.0,\n",
       " '7240.0': -1.0,\n",
       " '874.0': 0.0,\n",
       " '114276.0': 0.0,\n",
       " '7475.0': 33.0,\n",
       " '1296.0': -3.0,\n",
       " '17296.0': -2.0,\n",
       " '7289.0': 32.5,\n",
       " '2319.0': 3.0,\n",
       " '117006.0': 0.0,\n",
       " '10377.0': -8.0,\n",
       " '1980.0': -1.0,\n",
       " '10235.0': -1.5,\n",
       " '1059.0': 0.0,\n",
       " '3610.0': -1.0,\n",
       " '1987.0': -1.0,\n",
       " '11383.0': -6.0,\n",
       " '615.0': 4.0,\n",
       " '8713.0': 0.0,\n",
       " '6147.0': -2.0,\n",
       " 'new': 0.0}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####estimating the current warmth of incoming products\n",
    "\n",
    "###from the inbound datafame, add column 'estimate_temperature' to add the median temp. given the customer code\n",
    "\n",
    "###make a dictionary with customer code and its median temperature\n",
    "######get the median middle temperature of each customer code into a dataframe so you can \n",
    "warmthdf = pd.DataFrame({'customer_code': inbound['customer_code'], 'carrier_code': inbound['carrier_code'], 'middle_temperature': inbound['middle_temperature']})\n",
    "    ###filter through missing values/droplevel at missing values\n",
    "warmthdf = warmthdf.dropna()\n",
    "\n",
    "warmthdict = {}\n",
    "for customer in warmthdf.customer_code.unique():      ###per customercode, give the median middle_temperature\n",
    "    median = warmthdf.loc[warmthdf['customer_code'] == customer]\n",
    "    warmthdict[f'{customer}']=  median['middle_temperature'].median()\n",
    "\n",
    "warmthdict['new'] = warmthdf['middle_temperature'].median() ###add median temp for the customer_codes that are new\n",
    "\n",
    "###iterate over inbound and fill in the estimate_temperature \n",
    "for index, row in inbound.iterrows():\n",
    "    if inbound.at[index, 'middle_temperature'] >-5000: ####fill in the middle_temperature if that is known\n",
    "        inbound.at[index, 'estimate_temp'] = inbound.at[index, 'middle_temperature']\n",
    "       \n",
    "    else: ###else fill in the estimated temp. that belongs to the customer_code, unless it is not in the dict., then fill in 0.0 which is the median temp. of all the orders\n",
    "        code = inbound.at[index, 'customer_code']        \n",
    "        median = warmthdict.get(f'{code}', 0.0) \n",
    "        inbound.at[index, 'estimate_temp'] = median\n",
    "\n",
    "warmthdict\n",
    "###To check the different variances per customer_code: boxplot the different customer_code temperatures\n",
    "#warmthdf.assign(index=df.groupby('customer_code').cumcount()).pivot('index','customer_code','middle_temperature').plot(kind='box', figsize = [30,30])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "####estimating the current warmth of incoming products using sklearn ###THIS IS NOT WORKING/SHOULD I TRY?\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "###make warmthdf that consists of all the known middle temperature order entries\n",
    "warmthdf = pd.DataFrame({'customer_code': inbound['customer_code'], 'carrier_code': inbound['carrier_code'], 'middle_temperature': inbound['middle_temperature']})\n",
    "warmthdf = warmthdf.dropna()\n",
    "\n",
    "X = warmthdf['customer_code']\n",
    "\n",
    "y = warmthdf['middle_temperature']\n",
    "###IDK just split it into test and trainsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y ,\n",
    "                                   random_state=104, \n",
    "                                   test_size=0.25, \n",
    "                                   shuffle=True)\n",
    "\n",
    "#print(X_train)\n",
    "#### its categorical data because X is a category and you then want to estimate the y. \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "#regressor = DecisionTreeRegressor(random_state = 0) \n",
    "  \n",
    "# fit the regressor with X and Y data\n",
    "#regressor.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XXuGO5sMNXm8",
    "outputId": "976536a7-441f-4770-c483-43a2861db264"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "003    8608\n",
       "FOR    4982\n",
       "004    4347\n",
       "015    2640\n",
       "005    2607\n",
       "CFO    2459\n",
       "002    2216\n",
       "DR0    2051\n",
       "012    1911\n",
       "009    1370\n",
       "010    1199\n",
       "CP9    1088\n",
       "CP2    1037\n",
       "011     913\n",
       "INV     712\n",
       "001     599\n",
       "CP1     399\n",
       "CP6     241\n",
       "WRA     221\n",
       "014     151\n",
       "013      58\n",
       "DR9      49\n",
       "CP7      45\n",
       "SPJ      41\n",
       "263      26\n",
       "000      11\n",
       "CP4       8\n",
       "DR5       7\n",
       "UNA       4\n",
       "Name: tomovcat, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###pallet history contains where packages are going. Which packages are interesting? Testing above. Making it into a feature:\n",
    "\n",
    "###How many packages are entering a certain area at t as a feature for each location-type, we first make location types to and from\n",
    "    ###\n",
    "    ###How much time must be considered? 24-72h for blastfreezer, ideal: between in and out.\n",
    "    ###What locations to consider? Ignore forks/dock/\n",
    "    ###what locations can be considered the same, ideal: what locations have same temp.\n",
    "    \n",
    "    ##preprocessing the data:\n",
    "    ###some packages are already in the warehouse for a long time\n",
    "        #don't consider movements if the time between entranc and t is more than 72 hours because won't cost extra energy \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#df = df.assign(movcat = lambda x: (x[0:3]))\n",
    "#df = df.assign(movcat = lambda x: (x['to_location_code'][0:3])\n",
    "\n",
    "df = pallet[10000:50000]\n",
    "for index, row in df.iterrows():  \n",
    "        a = df.at[index, 'to_location_code']\n",
    "        b = df.at[index, 'from_location_code']\n",
    "        df.loc[index, 'frommovcat'] = b[0:3]\n",
    "        df.loc[index, 'tomovcat'] = a[0:3]\n",
    "df['tomovcat'].value_counts()\n",
    "\n",
    "\n",
    "###per movement type I will make one feature that defines how many pallets are moved towards a location. \n",
    "    #df = df.assign(Product=lambda x: (x['Field_1'] * x['Field_2'] * x['Field_3']))\n",
    "    \n",
    "\n",
    "###divide moving history into different category of areas. \n",
    "#mapping = {'(/^FORK/gm)': 'Fork', '(/^CFORK/gm)': 'CFORK', '(/^30/gm)' : '30', '(/^CP/gm)' : 'CP',  '(/^50/gm)' : '50',  '(/^15/gm)' : '15', '(/^11/gm)' : '11',  '(/^01/gm)' : '01' \n",
    "           \n",
    "\n",
    "    ### amount+1 for each order that entered the building within 24h\n",
    "#            if t <= inbound.at[index, 'load_start_datetime'] <= newtime :\n",
    "#                amount += measurewarmth(index, row)                            ### use measurewarmth to estimate the warmth that an entry brings in\n",
    "                \n",
    "#    return amount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "id": "5etBuOV3mniN",
    "outputId": "2346b0ac-3201-4761-8ba4-9e5f8c15be50"
   },
   "outputs": [],
   "source": [
    "\n",
    "###pallet types of locations:\n",
    "#003    2130\n",
    "#FOR    1177 \n",
    "#012    1116\n",
    "#011    1116\n",
    "#004    1024\n",
    "#005     619\n",
    "#CP9     566\n",
    "#DR0     483\n",
    "#CP2     371\n",
    "#CFO     282\n",
    "#010     200\n",
    "#009     174\n",
    "#INV     142\n",
    "#SPJ     133\n",
    "#CP1     126\n",
    "#CP6     109\n",
    "#002      69\n",
    "#WRA      60\n",
    "#001      47\n",
    "#015      40\n",
    "#CP7       8\n",
    "#CP4       5\n",
    "#DR9       2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
