{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prophet model training and predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, datetime, time, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import itertools\n",
    "import tqdm\n",
    "from prophet import Prophet\n",
    "\n",
    "\n",
    "def load_data(data_path):\n",
    "  data = pd.read_csv(data_path)  \n",
    "  return data\n",
    "\n",
    "inbound = load_data(\"inbound_loads.csv\")\n",
    "outbound = load_data(\"outbound_laods.csv\")\n",
    "weather = load_data(\"weather.csv\")\n",
    "#For loop to ensure that all pallet data is in the same dataframe\n",
    "pallet = load_data(\"Pallet_history_Gold_Spike[0].csv\")\n",
    "for x in range(1, 10):\n",
    "    pallet = pd.concat([pallet, load_data(f\"Pallet_history_Gold_Spike[{x}].csv\")])\n",
    "trainentest = load_data(\"demand_kWtrain_val.csv\")\n",
    "train = trainentest.iloc[:273988,:]\n",
    "topredict = trainentest.iloc[273988:, :]\n",
    "\n",
    "pallet = pallet.drop(['lot_code', \n",
    "                      'tran_type', \n",
    "                      'final_pallet_code', \n",
    "                      'warehouse_facility_id',\n",
    "                      'source_system_id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For alldates_df, concat the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldates_df = load_data('alldates_df.csv')\n",
    "alldates_df = alldates_df.rename(columns = {'Unnamed: 0':'datetime_local'})\n",
    "alldates_df['datetime_local'] = pd.to_datetime(alldates_df['datetime_local'])\n",
    "alldates_df = alldates_df.set_index('datetime_local')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create test and train dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column(df, columnname):\n",
    "    \"\"\"Function which returns a Dataframe where the given column is normalized through min-max normalization.\"\"\"\n",
    "    df[f'{columnname}_normalized'] = (df[columnname] - df[columnname].min()) / (df[columnname].max() - df[columnname].min())\n",
    "    return df.drop([columnname], axis=1)\n",
    "\n",
    "def add_one_hot_encoder(df, colname):\n",
    "    \"\"\"\n",
    "    Function which returns a DataFrame where the given column has been removed and replaced by\n",
    "    one-hot-encoding columns for each value in the original column.\n",
    "    \"\"\"\n",
    "    onehot = pd.get_dummies(df[colname], prefix=colname)\n",
    "    return df.drop(colname, axis=1).join(onehot)\n",
    "\n",
    "def interpolate_column(df, colname):\n",
    "    df[f'{colname}_interpolated'] = df[colname].interpolate(method='linear')\n",
    "    return df.drop([colname], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in the data\n",
    "all_data = load_data(\"train_test_features_df.csv\")\n",
    "print(all_data.shape)\n",
    "all_data['datetime_local'] = pd.to_datetime(all_data['datetime_local'])\n",
    "interpolate = ['Temperature', 'Relative Humidity']\n",
    "to_normalize = ['Relative Humidity_interpolated', 'Temperature_interpolated', 'weight_1h',  \n",
    "                'weight_5h', 'weight_10h', 'weight_23h', 'pallet_movement_5min', 'doors_open']\n",
    "add_one_hot_encoding = ['weekday', 'year', 'month']\n",
    "\n",
    "for x in interpolate:\n",
    "    all_data = interpolate_column(all_data, x)\n",
    "for x in to_normalize:\n",
    "    all_data = normalize_column(all_data, x)\n",
    "for x in add_one_hot_encoding:\n",
    "    all_data = add_one_hot_encoder(all_data, x)\n",
    "    \n",
    "all_data_train = all_data[all_data['datetime_local'] < '2021-10-11 06:08']\n",
    "all_data_predict = all_data[all_data['datetime_local'] >= '2021-10-11 06:08']\n",
    "predictions_dates = all_data_predict['datetime_local']\n",
    "all_data_predict = all_data_predict.drop('datetime_local', axis=1)\n",
    "all_data_train = interpolate_column(all_data_train, 'demand_kW')\n",
    "all_data_train = all_data_train.rename(columns={'demand_kW_interpolated': 'demand_kW'})\n",
    "all_data_predict = all_data_predict.drop('demand_kW', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet.plot import plot_plotly, plot_components_plotly\n",
    "\n",
    "\"\"\"\n",
    "Function to test prophet with\n",
    "all_df: all the data you have\n",
    "dummy_freq: frequency of datapoints you want the model to be fitted on test{day,hour,15min, 1 min}\n",
    "regressors: set of columns in new_df you want to give to the model\n",
    "cross_folds: amount of cross validation slices you want to use\n",
    "changepoint_prior_scales: flexibility of the model to fit\n",
    "\"\"\"\n",
    "\n",
    "def prophet_model_prediction(all_df, dummy_freq, regressors, n_splits = 5, changepoint_prior_scales = [0.05], add_month = False, add_hour = False):\n",
    "    \n",
    "    best_month_rmse = 100000000\n",
    "    ##make dic of all combinations of the regressors(this doesnt work fuckme)\n",
    "    #regressor_combinations = itertools.product(regressors)\n",
    "    regressor_combinations = regressors\n",
    "   \n",
    "    results = {}\n",
    "    all_df_forplotting = all_df.reset_index()\n",
    "    all_df_forplotting.rename(columns = {'index': 'ds'}, inplace = True)\n",
    "    all_df_formonthcheck = pd.DataFrame({'ds' : all_df_forplotting['ds'], 'demand_kW' : all_df_forplotting['demand_kW']})\n",
    "    \n",
    "    #for each frequency in dummy_freq, resample the new_df to contain datapoints with given frequency\n",
    "    for freq in dummy_freq:        \n",
    "        resampled_dummy_df = all_df.resample(freq).last()  \n",
    "        \n",
    "        \n",
    "        #for each regressor combination do the following\n",
    "        for regs in regressor_combinations:  \n",
    "            print(regs)\n",
    "            start = time.time()\n",
    "            prophet_dummy_df = pd.DataFrame({'ds': resampled_dummy_df.index, 'y' : resampled_dummy_df['demand_kW']})\n",
    "            ##create the prophet_dummy_df that contains the regressors, column ds, y and reset the index\n",
    "            for reg in regs: \n",
    "                \n",
    "                prophet_dummy_df[str(reg)] = resampled_dummy_df[reg].copy()\n",
    "                \n",
    "            prophet_dummy_df = prophet_dummy_df.reset_index()\n",
    "            prophet_dummy_df.drop(['index'], axis = 1, inplace = True)\n",
    "            \n",
    "            \n",
    "            ##do cross validation with n_splits\n",
    "            #ts = TimeSeriesSplit(n_splits=n_splits)\n",
    "            count = 1\n",
    "            train_rmses = []\n",
    "            test_rmses = []\n",
    "            for train, test in ts.split(prophet_dummy_df):              \n",
    "                print(f'Starting fold {count}')\n",
    "                \n",
    "                ##initiate a prophet object m and add each regressor to it\n",
    "                m = Prophet()\n",
    "                if add_month:\n",
    "                    m.add_seasonality(name='monthly', period=30.5, fourier_order=5)\n",
    "                if add_hour:\n",
    "                    m.add_seasonality(name='hourly', period=0.042, fourier_order=5)\n",
    "                for reg in regs:\n",
    "                    m.add_regressor(reg)\n",
    "                    \n",
    "                #create test and trainset                \n",
    "                cv_train, cv_test = prophet_dummy_df.iloc[train], prophet_dummy_df.iloc[test]                \n",
    "                future_test = cv_test.drop(['y'], axis = 1)\n",
    "                future_train = cv_train.drop(['y'], axis = 1)               \n",
    "\n",
    "                cv_train\n",
    "                #fit model\n",
    "                train_start = time.time()\n",
    "                m.fit(cv_train)\n",
    "                    \n",
    "                                          \n",
    "                train_stop = time.time()\n",
    "                \n",
    "                #to predict future, create df for the coming future month\n",
    "                predict_start = time.time()\n",
    "                month_future_minutes = m.make_future_dataframe(periods = 43000, freq = 'min', include_history = False)\n",
    "                for reg in regs:               \n",
    "                    all_df_formonthcheck[str(reg)] = all_df_forplotting[reg].copy()\n",
    "\n",
    "                month_future_minutes = month_future_minutes.merge(all_df_formonthcheck, on = 'ds', how = 'left') \n",
    "\n",
    "                y_pred_test = m.predict(future_test) \n",
    "                y_pred_train = m.predict(future_train)\n",
    "                y_pred_month = m.predict(month_future_minutes)\n",
    "                predict_stop = time.time()                \n",
    "                \n",
    "                #Calc rmse\n",
    "                rmse_start = time.time()\n",
    "                train_rmse = mean_squared_error(cv_train['y'], y_pred_train['yhat'], squared=False)\n",
    "                test_rmse = mean_squared_error(cv_test['y'], y_pred_test['yhat'], squared=False)                \n",
    "                month_rmse = mean_squared_error(month_future_minutes['demand_kW'], y_pred_month['yhat'], squared=False)\n",
    "                rmse_stop = time.time()        \n",
    "                train_rmses.append(train_rmse)\n",
    "                test_rmses.append(test_rmse)\n",
    "                \n",
    "                #print findings\n",
    "                timings = [(train_stop - train_start), (predict_stop - predict_start), (rmse_stop - rmse_start), (rmse_stop - train_start)]\n",
    "                print(\"these are the taken regulators:\",   regs)\n",
    "                print(f'Fold {count} train error: {train_rmse}. Test error: {test_rmse}. month error: {month_rmse}.Time taken: {timings[3]} s.')                    \n",
    "                count += 1\n",
    "                if month_rmse < best_month_rmse:\n",
    "                    best_month_rmse = month_rmse\n",
    "                    best_regs = regs\n",
    "                    best_train_rmse = train_rmse \n",
    "                    print(\"FUCKYES\", freq)\n",
    "                \n",
    "            all_rmses = [train_rmses, test_rmses]\n",
    "            m.plot(y_pred_month)\n",
    "        ##for each split, do the following\n",
    "            \n",
    "    return [m, test_rmse, all_rmses, timings]\n",
    "            \n",
    "        #print(f'Mean Absolute Error = {mae}')\n",
    "        #modelname = str(regressors) + 'with frequency' + str(freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Prophet model \n",
    "Createtrainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forresample = all_data_train.set_index('datetime_local')\n",
    "all_data_15min = forresample.copy().resample('15min').last()\n",
    "prophet_dummy_df = pd.DataFrame({'ds': all_data_15min.index, 'y' : all_data_15min['demand_kW']})\n",
    "prophet_dummy_df.reset_index(inplace= True)\n",
    "prophet_dummy_df.drop('datetime_local', axis = 1, inplace = True)\n",
    "prophet_dummy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create prediction set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = pd.DataFrame({'ds': all_data_predict['datetime_local'], 'datetime_local': all_data_predict['datetime_local']})\n",
    "prediction_df = prediction_df.set_index('datetime_local')\n",
    "prediction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model with the trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Prophet()\n",
    "m.fit(prophet_dummy_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions with the prediction set and plot the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_predictions = m.predict(prediction_df)\n",
    "m.plot(prophet_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_prophet['yhat'].to_csv('results_prophet.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demand values we have: 12/31/2018 21:15:00 upandincluding 10/11/2021/ 6:07:00\n",
    "Predicting the demand from 10/11/2021/ 6:08 upandincluding 12/13/2021 17:59:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test basic testing with 5 folds\n",
    "best next months prediction is 345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_model_prediction(new_df, ['15min'], [[]], n_splits = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_model_prediction(new_df, ['h'], [[]], n_splits = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_model_prediction(new_df, ['h'], [[]], n_splits = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test different regressors all together\n",
    "leads to overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_model_prediction(new_df, ['h'], [['weight_1h_normalized','Relative Humidity_interpolated_normalized',\n",
    "       'Temperature_interpolated_normalized', 'weight_1h_normalized',\n",
    "       'weight_5h_normalized', 'weight_10h_normalized',\n",
    "       'weight_23h_normalized', 'pallet_movement_5min_normalized',\n",
    "       'doors_open_normalized']], changepoint_prior_scales = [0.5])\n",
    "\n",
    "#prophet_model_prediction(new_df, '[h, 15min, d]',['Temperature_interpolated_normalized'] )\n",
    "#prophet_model_prediction(new_df,['Temperature_interpolated_normalized'] )\n",
    "#prophet_model_prediction(new_df,['Temperature_interpolated_normalized'] )\n",
    "\"\"\"\n",
    "['weight_1h_normalized','Relative Humidity_interpolated_normalized',\n",
    "       'Temperature_interpolated_normalized', 'weight_1h_normalized',\n",
    "       'weight_5h_normalized', 'weight_10h_normalized',\n",
    "       'weight_23h_normalized', 'pallet_movement_5min_normalized',\n",
    "       'doors_open_normalized']\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test all regressors individually\n",
    "findings summarized: each regressor adds very very little and creates a lower train error and test erorr but also more overfitting\n",
    "\n",
    "the train error is around 190-200 and the testerror is around 500 and the 2 months expectation error is around 237"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prophet_model_prediction(new_df, ['h'], [['weight_1h_normalized','Relative Humidity_interpolated_normalized',\n",
    "       'Temperature_interpolated_normalized', 'weight_1h_normalized',\n",
    "       'weight_5h_normalized', 'weight_10h_normalized',\n",
    "       'weight_23h_normalized', 'pallet_movement_5min_normalized',\n",
    "       'doors_open_normalized']], changepoint_prior_scales = [0.5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test for y2021 data\n",
    "findings, it is worse than using all years for both hour and 15 min frequency datapoints. \n",
    "for hour datafrequency and no regressors\n",
    "fold 2:\n",
    "Fold 2 train error: 303.91675967775853. Test error: 520.8706442095779. month error: 438.8608590535741\n",
    "\n",
    "for 15 min data and no regressors\n",
    "Fold 2 train error: 286.14426214818167. Test error: 512.0793509099431. month error: 435.20339042603246."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_model_prediction(y2021_df, ['h'], [[]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_model_prediction(y2021_df, ['15min'], [[]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test for all years data\n",
    "findings: overfitting is happening\n",
    "for hour frequency\n",
    "fold 2: train error 203, test error 418, month error 354\n",
    "\n",
    "for 15 minutes frequency\n",
    "fold 2: train error 200, test error 1107, month error 432 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_model_prediction(new_df, ['h'], [[]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_model_prediction(new_df, ['15min'], [[]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test to include month cycle/hour cycle\n",
    "when using allyears, hourly, add month = true,\n",
    "train error 202, test error 502, month error 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_model_prediction(new_df, ['h'], [[]], add_month = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using allyears, hourly, hour = true\n",
    "train error 202, test error 532, month error 363"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_model_prediction(new_df, ['h'], [[]], add_hour = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test different changepoint_prior_scales for Temp. \n",
    "Findings: there is no difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet_model_prediction(new_df, ['h'], [['Temperature_interpolated_normalized']], changepoint_prior_scales = [0.5, 0.1, 0.05])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
