{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries and Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6GgydedI6kRr"
   },
   "outputs": [],
   "source": [
    "import math, datetime, time, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import math, datetime, time, random\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import tqdm\n",
    "\n",
    "def load_data(data_path):\n",
    "    data = pd.read_csv(data_path)  \n",
    "    return data\n",
    "\n",
    "inbound = load_data(\"inbound_loads.csv\")\n",
    "outbound = load_data(\"outbound_laods.csv\")\n",
    "weather = load_data(\"weather.csv\")\n",
    "#For loop to ensure that all pallet data is in the same dataframe\n",
    "pallet = load_data(\"Pallet_history_Gold_Spike[0].csv\")\n",
    "for x in range(1, 10):\n",
    "    pallet = pd.concat([pallet, load_data(f\"Pallet_history_Gold_Spike[{x}].csv\")])\n",
    "pallet = pallet.drop(['lot_code', \n",
    "                      'tran_type', \n",
    "                      'final_pallet_code', \n",
    "                      'warehouse_facility_id',\n",
    "                      'source_system_id'], axis=1)\n",
    "trainentest = load_data(\"demand_kWtrain_val.csv\")\n",
    "train = trainentest.iloc[:273988,:]\n",
    "test = trainentest.iloc[273988:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwIsOHLEjdRk"
   },
   "source": [
    "# Preprocessing the Data\n",
    "### 1. Load features and get them into the base dataframe\n",
    "\n",
    "- load all features into the base dataframe\n",
    "- create base_df\n",
    "\n",
    "### 2. Preprocessing of features\n",
    "- create dummy\n",
    "- normalization (DECISION: Min-Max Normalization) \n",
    "- one hot encoding\n",
    "- interpolating (fill in in between values)\n",
    "\n",
    "### 3. Cutting off the dataframe \n",
    "DECISION: ? \n",
    "Which datapoints to keep?\n",
    "Pallet_movement_5min starts 2nd of Jan 2019, so first rows is NaN. \n",
    "\n",
    "-  Demand values we have:\n",
    "12/31/2018  21:15:00  upandincluding 10/11/2021/ 6:07:00\n",
    "-  Predicting the demand from \n",
    "10/11/2021/ 6:08 upandincluding 12/13/2021  17:59:00 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load features and get them into the base dataframe\n",
    "#### Load features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total weight of pallets coming into the warehouse in the previous 1h, 5h, 10h, 23h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Incoming weight feature preprocessing\n",
    "#load all data\n",
    "incoming_weight_1h = load_data('incoming_weight_df_1h.csv')\n",
    "incoming_weight_5h = load_data('incoming_weight_df_5h.csv')\n",
    "incoming_weight_10h = load_data('incoming_weight_df_10h.csv')\n",
    "incoming_weight_23h = load_data('incoming_weight_df.csv')\n",
    "#rename columns \n",
    "incoming_weight_5h = incoming_weight_5h.rename(columns = {'weight_23h' : 'weight_5h'})\n",
    "incoming_weight_1h = incoming_weight_1h.rename(columns = {'weight_23h' : 'weight_1h'})\n",
    "incoming_weight_10h = incoming_weight_10h.rename(columns = {'weight_23h' : 'weight_10h'})\n",
    "#get them to a datetime object\n",
    "incoming_weight_1h['datetime_local'] = pd.to_datetime(incoming_weight_1h['datetime_local'])\n",
    "incoming_weight_5h['datetime_local'] = pd.to_datetime(incoming_weight_5h['datetime_local'])\n",
    "incoming_weight_10h['datetime_local'] = pd.to_datetime(incoming_weight_10h['datetime_local'])\n",
    "incoming_weight_23h['datetime_local'] = pd.to_datetime(incoming_weight_23h['datetime_local'])\n",
    "#set index to be datetime\n",
    "incoming_weight_1h.set_index('datetime_local', inplace=True)\n",
    "incoming_weight_5h.set_index('datetime_local', inplace=True)\n",
    "incoming_weight_10h.set_index('datetime_local', inplace=True)\n",
    "incoming_weight_23h.set_index('datetime_local', inplace=True)\n",
    "#reshape them to start at 2018-31-12 9:15PM\n",
    "incoming_weight_1h = incoming_weight_1h[2361:]\n",
    "incoming_weight_5h = incoming_weight_5h[2330:] \n",
    "incoming_weight_10h = incoming_weight_10h[2326:]\n",
    "incoming_weight_23h = incoming_weight_23h[2323:]\n",
    "#Drop duplicates\n",
    "incoming_weight_1h = incoming_weight_1h.loc[~incoming_weight_1h.index.duplicated()]\n",
    "incoming_weight_5h = incoming_weight_5h.loc[~incoming_weight_5h.index.duplicated()]\n",
    "incoming_weight_10h = incoming_weight_10h.loc[~incoming_weight_10h.index.duplicated()]\n",
    "incoming_weight_23h = incoming_weight_23h.loc[~incoming_weight_23h.index.duplicated()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of pallets moved within 5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "pallet_move_5min = load_data('pallet_movement_5min_ft.csv')\n",
    "#rename column\n",
    "pallet_move_5min.rename(columns = {'quantity' : 'pallet_movement_5min'}, inplace = True)\n",
    "#make index a datetime object and set as index\n",
    "pallet_move_5min['datetime_local'] = pd.to_datetime(pallet_move_5min['datetime_local'])\n",
    "pallet_move_5min.set_index('datetime_local', inplace = True)\n",
    "#delete duplicates\n",
    "pallet_move_5min = pallet_move_5min.loc[~pallet_move_5min.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_door = load_data(\"feature_inbound_outbound_door_open.csv\")\n",
    "base_door = base_door.rename(columns = {'total' : 'doors_open'})\n",
    "base_door['datetime_local'] = pd.to_datetime(base_door['datetime_local'])\n",
    "base_door.set_index('datetime_local', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the base dataframe base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XXuGO5sMNXm8",
    "outputId": "976536a7-441f-4770-c483-43a2861db264"
   },
   "outputs": [],
   "source": [
    "def addtimecol(df, colname): ####input df and colname \n",
    "    df[colname] = pd.to_datetime(df[colname])         \n",
    "    df['year'] = df[colname].dt.year\n",
    "    df['month'] = df[colname].dt.month\n",
    "    df['weekday'] = df[colname].dt.weekday\n",
    "    df['day'] = df[colname].dt.day\n",
    "    df['hour'] = df[colname].dt.hour\n",
    "    df['minute'] = df[colname].dt.minute        \n",
    "    return df\n",
    "\n",
    "#Create new dummy dfs\n",
    "base_df = train.copy()\n",
    "base_weather = weather.copy()\n",
    "\n",
    "#Remove unnecessary columns\n",
    "base_df = base_df.drop('Unnamed: 0', axis=1)\n",
    "base_weather = base_weather.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n",
    "base_weather[\"localstrptime\"]= pd.to_datetime(base_weather[\"localstrptime\"])\n",
    "base_df['datetime_local'] = pd.to_datetime(base_df['datetime_local'])\n",
    "base_weather = base_weather.rename(columns={'localstrptime':'datetime_local'})\n",
    "\n",
    "#Add time columns.\n",
    "addtimecol(base_df, 'datetime_local')\n",
    "\n",
    "#Set index to datetime\n",
    "base_df.set_index('datetime_local', inplace=True)\n",
    "base_weather.set_index('datetime_local', inplace=True)\n",
    "\n",
    "#Concatenate the weather DataFrame to the base DataFrame\n",
    "base_df = pd.concat([base_df, base_weather], axis=1)\n",
    "\n",
    "#Concatenate the incoming weight dataframe with the base dataframe\n",
    "base_df = pd.concat([base_df, incoming_weight_1h], axis=1)\n",
    "base_df = pd.concat([base_df, incoming_weight_5h], axis=1)\n",
    "base_df = pd.concat([base_df, incoming_weight_10h], axis=1)\n",
    "base_df = pd.concat([base_df, incoming_weight_23h], axis=1)\n",
    "\n",
    "#Concatenate the pallet movement feature\n",
    "base_df = pd.concat([base_df, pallet_move_5min], axis = 1)\n",
    "\n",
    "#Concatenate the door feature\n",
    "base_df = pd.concat([base_df, base_door], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing of features\n",
    "\n",
    "#### Creating the dummy df with which we will do model selection\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "id": "5etBuOV3mniN",
    "outputId": "2346b0ac-3201-4761-8ba4-9e5f8c15be50"
   },
   "outputs": [],
   "source": [
    "dummy_df = base_df.copy()\n",
    "dummy_df = dummy_df.reset_index()\n",
    "dummy_df = dummy_df.drop(['hour'], axis=1)\n",
    "dummy_df = dummy_df.drop(['datetime'], axis=1)\n",
    "dummy_df = dummy_df.drop(['datetime_local'], axis=1)\n",
    "dummy_df = dummy_df.drop(['datetime_UTC'], axis=1)\n",
    "dummy_df\n",
    "\n",
    "dummy_normalized_df = dummy_df.copy()\n",
    "#Still drop demand_kW NaNs\n",
    "dummy_normalized_df = dummy_normalized_df.dropna(subset=['demand_kW'], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing functions defined\n",
    "DECISION: MinMax Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column(df, columnname):\n",
    "    \"\"\"Function which returns a Dataframe where the given column is normalized through min-max normalization.\"\"\"\n",
    "    df[f'{columnname}_normalized'] = (df[columnname] - df[columnname].min()) / (df[columnname].max() - df[columnname].min())\n",
    "    return df.drop([columnname], axis=1)\n",
    "\n",
    "def add_one_hot_encoder(df, colname):\n",
    "    \"\"\"\n",
    "    Function which returns a DataFrame where the given column has been removed and replaced by\n",
    "    one-hot-encoding columns for each value in the original column.\n",
    "    \"\"\"\n",
    "    onehot = pd.get_dummies(df[colname], prefix=colname)\n",
    "    return df.drop(colname, axis=1).join(onehot)\n",
    "\n",
    "def interpolate_column(df, colname):\n",
    "    df[f'{colname}_interpolated'] = df[colname].interpolate(method='linear')\n",
    "    return df.drop([colname], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### interpolate/one-hot-encoding/normalizing\n",
    "DECISION: ?  normalization of the doors_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolate = ['Temperature', 'Relative Humidity']\n",
    "to_normalize = ['Relative Humidity_interpolated', 'Temperature_interpolated', 'weight_23h','weight_10h', 'weight_5h', 'weight_1h', 'pallet_movement_5min', 'doors_open']\n",
    "add_one_hot_encoding = ['weekday', 'year', 'month']\n",
    "\n",
    "\n",
    "for x in interpolate:\n",
    "    dummy_normalized_df = interpolate_column(dummy_normalized_df, x)\n",
    "for x in to_normalize:\n",
    "    dummy_normalized_df = normalize_column(dummy_normalized_df, x)\n",
    "for x in add_one_hot_encoding:\n",
    "    dummy_normalized_df = add_one_hot_encoder(dummy_normalized_df, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create timeseries dummy + method for adding lags of a cycle we want to model\n",
    "##### timeseries_dummy only consists of the range of dates we have for which we have information per minute, because timeseries need to have regular intervals. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create timeseries_dummy \n",
    "starttime = trainentest['datetime_local'].at[79678]\n",
    "startime = pd.to_datetime(starttime)\n",
    "onlyminutesstep1 = base_df[:1460735]\n",
    "onlyminutes = onlyminutesstep1.loc[starttime:]\n",
    "timeseries_dummy = onlyminutes.copy()\n",
    "\n",
    "### Create rows for missing minutes\n",
    "timeseries_dummy = timeseries_dummy.asfreq(freq = 'T', method = 'pad')\n",
    "\n",
    "### about 6900 random rows don't have demand, ffill is fill them with the previous amount\n",
    "timeseries_dummy['demand_kW'] = timeseries_dummy.demand_kW.fillna(method = 'ffill', axis = 0)\n",
    "\n",
    "### edit timeseries_dummy just as dummy_dataset\n",
    "timeseries_dummy.reset_index(inplace = True)\n",
    "timeseries_dummy.drop(['hour'], axis=1, inplace = True)\n",
    "timeseries_dummy.drop(['datetime'], axis=1, inplace = True)\n",
    "timeseries_dummy.drop(['datetime_local'], axis=1, inplace = True)\n",
    "timeseries_dummy.drop(['datetime_UTC'], axis=1, inplace = True)\n",
    "\n",
    "### setup a normalized dataframe\n",
    "timeseries_normalized_dummy = timeseries_dummy.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A method to create 'lags' of a series; aka previous values in a cycle.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These values are added as columns to the timeseries_dummy\n",
    "#The amount of columns that are added are the amount of lags\n",
    "#The column used is in the list [col_names]\n",
    "#The period of which the previous timepoint is taken are the amount of minutes before it, so cycle of a day is 60x24 minutes\n",
    "\n",
    "def add_lags_of_column(df, col_names, lag = 3, period = 1):\n",
    "    new_dict={}\n",
    "    for col_name in col_names:\n",
    "        new_dict[col_name]=df[col_name]\n",
    "        # create lagged Series\n",
    "        for l in range(1,lag+1):\n",
    "            new_dict['%s_%amin_%d' %(col_name, period,l)]=df[col_name].shift(l*period)\n",
    "    return pd.DataFrame(new_dict,index=df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using method above to add a daycycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_kW</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day</th>\n",
       "      <th>minute</th>\n",
       "      <th>Relative Humidity</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>weight_1h</th>\n",
       "      <th>weight_5h</th>\n",
       "      <th>...</th>\n",
       "      <th>demand_kW_1440min_1</th>\n",
       "      <th>demand_kW_1440min_2</th>\n",
       "      <th>demand_kW_1440min_3</th>\n",
       "      <th>demand_kW_1440min_4</th>\n",
       "      <th>demand_kW_1440min_5</th>\n",
       "      <th>demand_kW_1440min_6</th>\n",
       "      <th>demand_kW_1440min_7</th>\n",
       "      <th>demand_kW_1440min_8</th>\n",
       "      <th>demand_kW_1440min_9</th>\n",
       "      <th>demand_kW_1440min_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1334.544</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88553.0</td>\n",
       "      <td>478724.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1302.755</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>71.6</td>\n",
       "      <td>88553.0</td>\n",
       "      <td>478724.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1407.071</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88553.0</td>\n",
       "      <td>478724.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1328.769</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88553.0</td>\n",
       "      <td>478724.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1413.847</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88553.0</td>\n",
       "      <td>478724.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201239</th>\n",
       "      <td>2217.847</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26159.0</td>\n",
       "      <td>333431.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2083.348</td>\n",
       "      <td>2454.500</td>\n",
       "      <td>2664.214</td>\n",
       "      <td>2576.234</td>\n",
       "      <td>2320.085</td>\n",
       "      <td>2490.769</td>\n",
       "      <td>2404.005</td>\n",
       "      <td>2366.596</td>\n",
       "      <td>2654.723</td>\n",
       "      <td>2358.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201240</th>\n",
       "      <td>2184.012</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26159.0</td>\n",
       "      <td>333431.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2089.805</td>\n",
       "      <td>2452.624</td>\n",
       "      <td>2653.190</td>\n",
       "      <td>2560.751</td>\n",
       "      <td>2191.568</td>\n",
       "      <td>2458.903</td>\n",
       "      <td>2413.946</td>\n",
       "      <td>2393.992</td>\n",
       "      <td>2697.868</td>\n",
       "      <td>2382.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201241</th>\n",
       "      <td>2159.482</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>87.75</td>\n",
       "      <td>57.2</td>\n",
       "      <td>26159.0</td>\n",
       "      <td>318331.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2132.082</td>\n",
       "      <td>2497.049</td>\n",
       "      <td>2637.603</td>\n",
       "      <td>2549.844</td>\n",
       "      <td>2130.947</td>\n",
       "      <td>2412.434</td>\n",
       "      <td>2431.350</td>\n",
       "      <td>2426.633</td>\n",
       "      <td>2723.577</td>\n",
       "      <td>2394.729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201242</th>\n",
       "      <td>2145.155</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26159.0</td>\n",
       "      <td>277345.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2135.021</td>\n",
       "      <td>2587.285</td>\n",
       "      <td>2648.607</td>\n",
       "      <td>2554.448</td>\n",
       "      <td>2102.054</td>\n",
       "      <td>2408.541</td>\n",
       "      <td>2429.524</td>\n",
       "      <td>2472.633</td>\n",
       "      <td>2737.067</td>\n",
       "      <td>2392.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201243</th>\n",
       "      <td>2213.599</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26159.0</td>\n",
       "      <td>277345.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2163.637</td>\n",
       "      <td>2652.302</td>\n",
       "      <td>2633.161</td>\n",
       "      <td>2561.868</td>\n",
       "      <td>2085.779</td>\n",
       "      <td>2415.147</td>\n",
       "      <td>2421.673</td>\n",
       "      <td>2518.865</td>\n",
       "      <td>2778.013</td>\n",
       "      <td>2431.376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201244 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        demand_kW    year  month  weekday   day  minute  Relative Humidity  \\\n",
       "0        1334.544  2021.0    5.0      0.0  24.0     4.0                NaN   \n",
       "1        1302.755  2021.0    5.0      0.0  24.0     5.0             100.00   \n",
       "2        1407.071  2021.0    5.0      0.0  24.0     6.0                NaN   \n",
       "3        1328.769  2021.0    5.0      0.0  24.0     7.0                NaN   \n",
       "4        1413.847  2021.0    5.0      0.0  24.0     8.0                NaN   \n",
       "...           ...     ...    ...      ...   ...     ...                ...   \n",
       "201239   2217.847  2021.0   10.0      0.0  11.0     3.0                NaN   \n",
       "201240   2184.012  2021.0   10.0      0.0  11.0     4.0                NaN   \n",
       "201241   2159.482  2021.0   10.0      0.0  11.0     5.0              87.75   \n",
       "201242   2145.155  2021.0   10.0      0.0  11.0     6.0                NaN   \n",
       "201243   2213.599  2021.0   10.0      0.0  11.0     7.0                NaN   \n",
       "\n",
       "        Temperature  weight_1h  weight_5h  ...  demand_kW_1440min_1  \\\n",
       "0               NaN    88553.0   478724.0  ...                  NaN   \n",
       "1              71.6    88553.0   478724.0  ...                  NaN   \n",
       "2               NaN    88553.0   478724.0  ...                  NaN   \n",
       "3               NaN    88553.0   478724.0  ...                  NaN   \n",
       "4               NaN    88553.0   478724.0  ...                  NaN   \n",
       "...             ...        ...        ...  ...                  ...   \n",
       "201239          NaN    26159.0   333431.0  ...             2083.348   \n",
       "201240          NaN    26159.0   333431.0  ...             2089.805   \n",
       "201241         57.2    26159.0   318331.0  ...             2132.082   \n",
       "201242          NaN    26159.0   277345.0  ...             2135.021   \n",
       "201243          NaN    26159.0   277345.0  ...             2163.637   \n",
       "\n",
       "        demand_kW_1440min_2  demand_kW_1440min_3  demand_kW_1440min_4  \\\n",
       "0                       NaN                  NaN                  NaN   \n",
       "1                       NaN                  NaN                  NaN   \n",
       "2                       NaN                  NaN                  NaN   \n",
       "3                       NaN                  NaN                  NaN   \n",
       "4                       NaN                  NaN                  NaN   \n",
       "...                     ...                  ...                  ...   \n",
       "201239             2454.500             2664.214             2576.234   \n",
       "201240             2452.624             2653.190             2560.751   \n",
       "201241             2497.049             2637.603             2549.844   \n",
       "201242             2587.285             2648.607             2554.448   \n",
       "201243             2652.302             2633.161             2561.868   \n",
       "\n",
       "        demand_kW_1440min_5  demand_kW_1440min_6  demand_kW_1440min_7  \\\n",
       "0                       NaN                  NaN                  NaN   \n",
       "1                       NaN                  NaN                  NaN   \n",
       "2                       NaN                  NaN                  NaN   \n",
       "3                       NaN                  NaN                  NaN   \n",
       "4                       NaN                  NaN                  NaN   \n",
       "...                     ...                  ...                  ...   \n",
       "201239             2320.085             2490.769             2404.005   \n",
       "201240             2191.568             2458.903             2413.946   \n",
       "201241             2130.947             2412.434             2431.350   \n",
       "201242             2102.054             2408.541             2429.524   \n",
       "201243             2085.779             2415.147             2421.673   \n",
       "\n",
       "        demand_kW_1440min_8  demand_kW_1440min_9  demand_kW_1440min_10  \n",
       "0                       NaN                  NaN                   NaN  \n",
       "1                       NaN                  NaN                   NaN  \n",
       "2                       NaN                  NaN                   NaN  \n",
       "3                       NaN                  NaN                   NaN  \n",
       "4                       NaN                  NaN                   NaN  \n",
       "...                     ...                  ...                   ...  \n",
       "201239             2366.596             2654.723              2358.351  \n",
       "201240             2393.992             2697.868              2382.798  \n",
       "201241             2426.633             2723.577              2394.729  \n",
       "201242             2472.633             2737.067              2392.788  \n",
       "201243             2518.865             2778.013              2431.376  \n",
       "\n",
       "[201244 rows x 25 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_daycycle = add_lags_of_column(timeseries_dummy, ['demand_kW'], 10, 1440)\n",
    "#add_hourcycle = add_lags_of_column(timeseries_dummy, ['demand_kW'], 10, 60)\n",
    "#add_weekcycle = add_lags_of_column(timeseries_dummy, ['demand_kW'], 10, 10080)\n",
    "\n",
    "pd.concat([timeseries_dummy, add_daycycle], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize timeseries_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolate = ['Temperature', 'Relative Humidity']\n",
    "to_normalize = ['Relative Humidity_interpolated', 'Temperature_interpolated', 'weight_23h','weight_10h', 'weight_5h', 'weight_1h', 'pallet_movement_5min', 'doors_open']\n",
    "add_one_hot_encoding = ['weekday', 'year', 'month']\n",
    "\n",
    "\n",
    "for x in interpolate:\n",
    "    timeseries_normalized_dummy = interpolate_column(timeseries_normalized_dummy, x)\n",
    "for x in to_normalize:\n",
    "    timeseries_normalized_dummy = normalize_column(timeseries_normalized_dummy, x)\n",
    "for x in add_one_hot_encoding:\n",
    "    timeseries_normalized_dummy = add_one_hot_encoder(timeseries_normalized_dummy, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection and building\n",
    "## 1. Importing model libraries\n",
    "\n",
    "## 2. Divide Train and Test data\n",
    "\n",
    "## 3. Test models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dividing train & test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, data, debug=False):\n",
    "    xtrain, ytrain, xtest, ytest = data\n",
    "    if debug:\n",
    "        print(\"Fitting model...\")\n",
    "    model.fit(xtrain, ytrain)\n",
    "    if debug:\n",
    "        print('Predicting...')\n",
    "    acc = model.predict(xtest)\n",
    "    if debug:\n",
    "        print('Calculating mean absolute error...')\n",
    "    return mean_absolute_error(list(ytest), acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### dummy_normalized_df['pallet_movement_5min'] drop NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_normalized_df = dummy_normalized_df.dropna(subset = ['pallet_movement_5min_normalized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define train, test sets\\n\",\n",
    "train, test = train_test_split(dummy_normalized_df, shuffle=True)\n",
    "X_train = train.copy().drop(['demand_kW'], axis=1)\n",
    "Y_train = train['demand_kW']\n",
    "X_test = test.copy().drop(['demand_kW'], axis=1)\n",
    "Y_test = test['demand_kW']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing\n",
    "\n",
    "### Use the find_optimal_parameters function imported from model_features.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_settings = {\n",
    "    'n_estimators': [10, 20],\n",
    "    #'criterion': ['squared_error', 'friedman_mse', 'squared_error', 'poisson'],\n",
    "    #'max_depth': [2, 4, 6],\n",
    "    #'min_samples_split': [2, 4, 8]\n",
    "}\n",
    "data = [X_train, Y_train, X_test, Y_test]\n",
    "model = RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model Model 1 with parameters: {'n_estimators': 10}\n",
      "Starting fold 1\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 45.93951387187146. Test error: 656.6920876372201. Time taken: 5.792354345321655 s.\n",
      "Starting fold 2\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 42.8272329452065. Test error: 529.2718317333357. Time taken: 11.185985088348389 s.\n",
      "Finished testing model. Test RMSE: 529.2718317333357. Time taken: 16.978339433670044.\n",
      "Testing model Model 2 with parameters: {'n_estimators': 20}\n",
      "Starting fold 1\n",
      "Training model...\n"
     ]
    }
   ],
   "source": [
    "from model_features import read_model\n",
    "from model_features import find_optimal_parameters\n",
    "from model_features import run_timeseries_model\n",
    "\n",
    "find_optimal_parameters(dummy_normalized_df, model, parameter_settings, n_splits=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
