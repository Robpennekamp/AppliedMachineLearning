{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries and Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6GgydedI6kRr"
   },
   "outputs": [],
   "source": [
    "import math, datetime, time, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import math, datetime, time, random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def load_data(data_path):\n",
    "    data = pd.read_csv(data_path)  \n",
    "    return data\n",
    "\n",
    "inbound = load_data(\"inbound_loads.csv\")\n",
    "outbound = load_data(\"outbound_laods.csv\")\n",
    "weather = load_data(\"weather.csv\")\n",
    "#For loop to ensure that all pallet data is in the same dataframe\n",
    "pallet = load_data(\"Pallet_history_Gold_Spike[0].csv\")\n",
    "for x in range(1, 10):\n",
    "    pallet = pd.concat([pallet, load_data(f\"Pallet_history_Gold_Spike[{x}].csv\")])\n",
    "pallet = pallet.drop(['lot_code', \n",
    "                      'tran_type', \n",
    "                      'final_pallet_code', \n",
    "                      'warehouse_facility_id',\n",
    "                      'source_system_id'], axis=1)\n",
    "trainentest = load_data(\"demand_kWtrain_val.csv\")\n",
    "train = trainentest.iloc[:273988,:]\n",
    "test = trainentest.iloc[273988:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwIsOHLEjdRk"
   },
   "source": [
    "## Load features and prepare them\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total weight of pallets coming into the warehouse in the previous 1h, 5h, 10h, 23h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Incoming weight feature preprocessing\n",
    "#load all data\n",
    "incoming_weight_1h = load_data('incoming_weight_df_1h.csv')\n",
    "incoming_weight_5h = load_data('incoming_weight_df_5h.csv')\n",
    "incoming_weight_10h = load_data('incoming_weight_df_10h.csv')\n",
    "incoming_weight_23h = load_data('incoming_weight_df.csv')\n",
    "#rename columns \n",
    "incoming_weight_5h = incoming_weight_5h.rename(columns = {'weight_23h' : 'weight_5h'})\n",
    "incoming_weight_1h = incoming_weight_1h.rename(columns = {'weight_23h' : 'weight_1h'})\n",
    "incoming_weight_10h = incoming_weight_10h.rename(columns = {'weight_23h' : 'weight_10h'})\n",
    "#get them to a datetime object\n",
    "incoming_weight_1h['datetime_local'] = pd.to_datetime(incoming_weight_1h['datetime_local'])\n",
    "incoming_weight_5h['datetime_local'] = pd.to_datetime(incoming_weight_5h['datetime_local'])\n",
    "incoming_weight_10h['datetime_local'] = pd.to_datetime(incoming_weight_10h['datetime_local'])\n",
    "incoming_weight_23h['datetime_local'] = pd.to_datetime(incoming_weight_23h['datetime_local'])\n",
    "#set index to be datetime\n",
    "incoming_weight_1h.set_index('datetime_local', inplace=True)\n",
    "incoming_weight_5h.set_index('datetime_local', inplace=True)\n",
    "incoming_weight_10h.set_index('datetime_local', inplace=True)\n",
    "incoming_weight_23h.set_index('datetime_local', inplace=True)\n",
    "#reshape them to start at 2018-31-12 9:15PM\n",
    "incoming_weight_1h = incoming_weight_1h[2361:]\n",
    "incoming_weight_5h = incoming_weight_5h[2330:] \n",
    "incoming_weight_10h = incoming_weight_10h[2326:]\n",
    "incoming_weight_23h = incoming_weight_23h[2323:]\n",
    "#Drop duplicates\n",
    "incoming_weight_1h = incoming_weight_1h.loc[~incoming_weight_1h.index.duplicated()]\n",
    "incoming_weight_5h = incoming_weight_5h.loc[~incoming_weight_5h.index.duplicated()]\n",
    "incoming_weight_10h = incoming_weight_10h.loc[~incoming_weight_10h.index.duplicated()]\n",
    "incoming_weight_23h = incoming_weight_23h.loc[~incoming_weight_23h.index.duplicated()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of pallets moved within 5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "pallet_move_5min = load_data('pallet_movement_5min_ft.csv')\n",
    "#rename column\n",
    "pallet_move_5min.rename(columns = {'quantity' : 'pallet_movement_5min'}, inplace = True)\n",
    "#make index a datetime object and set as index\n",
    "pallet_move_5min['datetime_local'] = pd.to_datetime(pallet_move_5min['datetime_local'])\n",
    "pallet_move_5min.set_index('datetime_local', inplace = True)\n",
    "#delete duplicates\n",
    "pallet_move_5min = pallet_move_5min.loc[~pallet_move_5min.index.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the base dataframe base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XXuGO5sMNXm8",
    "outputId": "976536a7-441f-4770-c483-43a2861db264"
   },
   "outputs": [],
   "source": [
    "def addtimecol(df, colname): ####input df and colname \n",
    "    df[colname] = pd.to_datetime(df[colname])         \n",
    "    df['year'] = df[colname].dt.year\n",
    "    df['month'] = df[colname].dt.month\n",
    "    df['weekday'] = df[colname].dt.weekday\n",
    "    df['day'] = df[colname].dt.day\n",
    "    df['hour'] = df[colname].dt.hour\n",
    "    df['minute'] = df[colname].dt.minute        \n",
    "    return df\n",
    "\n",
    "#Create new dummy dfs\n",
    "base_df = train.copy()\n",
    "base_weather = weather.copy()\n",
    "\n",
    "#Remove unnecessary columns\n",
    "base_df = base_df.drop('Unnamed: 0', axis=1)\n",
    "base_weather = base_weather.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n",
    "base_weather[\"localstrptime\"]= pd.to_datetime(base_weather[\"localstrptime\"])\n",
    "base_df['datetime_local'] = pd.to_datetime(base_df['datetime_local'])\n",
    "base_weather = base_weather.rename(columns={'localstrptime':'datetime_local'})\n",
    "\n",
    "#Add time columns.\n",
    "addtimecol(base_df, 'datetime_local')\n",
    "\n",
    "#Set index to datetime\n",
    "base_df.set_index('datetime_local', inplace=True)\n",
    "base_weather.set_index('datetime_local', inplace=True)\n",
    "\n",
    "#Concatenate the weather DataFrame to the base DataFrame\n",
    "base_df = pd.concat([base_df, base_weather], axis=1)\n",
    "\n",
    "#Concatenate the incoming weight dataframe with the base dataframe\n",
    "base_df = pd.concat([base_df, incoming_weight_1h], axis=1)\n",
    "base_df = pd.concat([base_df, incoming_weight_5h], axis=1)\n",
    "base_df = pd.concat([base_df, incoming_weight_10h], axis=1)\n",
    "base_df = pd.concat([base_df, incoming_weight_23h], axis=1)\n",
    "\n",
    "#Concatenate the pallet movement feature\n",
    "base_df = pd.concat([base_df, pallet_move_5min], axis = 1)\n",
    "\n",
    "\n",
    "# Drop all NaN values\n",
    "#base_df.dropna(subset=['demand_kW'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the dummy df and dropping necessary NaN rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "id": "5etBuOV3mniN",
    "outputId": "2346b0ac-3201-4761-8ba4-9e5f8c15be50"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_kW</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day</th>\n",
       "      <th>minute</th>\n",
       "      <th>Relative Humidity</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2064.101392</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>61.27</td>\n",
       "      <td>46.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1874.002081</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>61.27</td>\n",
       "      <td>46.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1988.168511</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>65.60</td>\n",
       "      <td>44.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022.795943</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.60</td>\n",
       "      <td>44.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1986.981872</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>65.60</td>\n",
       "      <td>44.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116228</th>\n",
       "      <td>2527.739000</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>87.75</td>\n",
       "      <td>57.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116229</th>\n",
       "      <td>2359.505000</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>83.84</td>\n",
       "      <td>57.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116230</th>\n",
       "      <td>2156.104000</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>87.75</td>\n",
       "      <td>57.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116231</th>\n",
       "      <td>2259.711000</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.75</td>\n",
       "      <td>57.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116232</th>\n",
       "      <td>2159.482000</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>87.75</td>\n",
       "      <td>57.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116233 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          demand_kW    year  month  weekday   day  minute  Relative Humidity  \\\n",
       "0       2064.101392  2018.0   12.0      0.0  31.0    15.0              61.27   \n",
       "1       1874.002081  2018.0   12.0      0.0  31.0    30.0              61.27   \n",
       "2       1988.168511  2018.0   12.0      0.0  31.0    45.0              65.60   \n",
       "3       2022.795943  2018.0   12.0      0.0  31.0     0.0              65.60   \n",
       "4       1986.981872  2018.0   12.0      0.0  31.0    15.0              65.60   \n",
       "...             ...     ...    ...      ...   ...     ...                ...   \n",
       "116228  2527.739000  2021.0   10.0      0.0  11.0    50.0              87.75   \n",
       "116229  2359.505000  2021.0   10.0      0.0  11.0    53.0              83.84   \n",
       "116230  2156.104000  2021.0   10.0      0.0  11.0    55.0              87.75   \n",
       "116231  2259.711000  2021.0   10.0      0.0  11.0     0.0              87.75   \n",
       "116232  2159.482000  2021.0   10.0      0.0  11.0     5.0              87.75   \n",
       "\n",
       "        Temperature  \n",
       "0             46.40  \n",
       "1             46.40  \n",
       "2             44.60  \n",
       "3             44.60  \n",
       "4             44.60  \n",
       "...             ...  \n",
       "116228        57.20  \n",
       "116229        57.92  \n",
       "116230        57.20  \n",
       "116231        57.20  \n",
       "116232        57.20  \n",
       "\n",
       "[116233 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_df = base_df.dropna(subset=['demand_kW'])\n",
    "\n",
    "####### DELETE THIS AFTERWARDS - TEMPORARY REMOVAL OF TIMES WITH NO TEMP OR Humidity\n",
    "#dummy_df = dummy_df.dropna(subset=['Temperature', 'Relative Humidity'])\n",
    "\n",
    "dummy_df = dummy_df.reset_index()\n",
    "dummy_df = dummy_df.drop(['hour'], axis=1)\n",
    "dummy_df = dummy_df.drop(['datetime'], axis=1)\n",
    "dummy_df = dummy_df.drop(['datetime_local'], axis=1)\n",
    "dummy_df = dummy_df.drop(['datetime_UTC'], axis=1)\n",
    "dummy_df\n",
    "\n",
    "\n",
    "dummy_normalized_df = dummy_df.copy()\n",
    "#Still drop demand_kW NaNs\n",
    "dummy_normalized_df = dummy_normalized_df.dropna(subset=['demand_kW'], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection and building\n",
    "## Importing model libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing train & test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define train, test sets\\n\",\n",
    "train, test = train_test_split(dummy_df)\n",
    "X_train = train.copy().drop(['demand_kW'], axis=1)\n",
    "Y_train = train['demand_kW']\n",
    "X_test = test.copy().drop(['demand_kW'], axis=1)\n",
    "Y_test = test['demand_kW']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regression\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_train, Y_train)\n",
    "rfr_acc = rfr.predict(X_test)\n",
    "print(r2_score(list(Y_test), rfr_acc))\n",
    "print(mean_absolute_error(list(Y_test), rfr_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
