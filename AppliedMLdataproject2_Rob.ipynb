{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6GgydedI6kRr",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math, datetime, time, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import itertools\n",
    "import tqdm\n",
    "\n",
    "\n",
    "def load_data(data_path):\n",
    "  data = pd.read_csv(data_path)  \n",
    "  return data\n",
    "\n",
    "inbound = load_data(\"inbound_loads.csv\")\n",
    "outbound = load_data(\"outbound_laods.csv\")\n",
    "weather = load_data(\"weather.csv\")\n",
    "#For loop to ensure that all pallet data is in the same dataframe\n",
    "pallet = load_data(\"Pallet_history_Gold_Spike[0].csv\")\n",
    "for x in range(1, 10):\n",
    "    pallet = pd.concat([pallet, load_data(f\"Pallet_history_Gold_Spike[{x}].csv\")])\n",
    "pallet = pallet.drop(['lot_code', \n",
    "                      'tran_type', \n",
    "                      'final_pallet_code', \n",
    "                      'warehouse_facility_id',\n",
    "                      'source_system_id'], axis=1)\n",
    "trainentest = load_data(\"demand_kWtrain_val.csv\")\n",
    "train = trainentest.iloc[:273988,:]\n",
    "test = trainentest.iloc[273988:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weekend(x):\n",
    "    if x['weekday'] > 4:\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "\n",
    "def addtimecol(df, colname): ####input df and colname \n",
    "    df[colname] = pd.to_datetime(df[colname])         \n",
    "    df['year'] = df[colname].dt.year\n",
    "    df['month'] = df[colname].dt.month\n",
    "    df['weekday'] = df[colname].dt.weekday\n",
    "    df['weekend'] = df.apply(weekend, axis=1)\n",
    "    df['day'] = df[colname].dt.day\n",
    "    df['hour'] = df[colname].dt.hour\n",
    "    df['minute'] = df[colname].dt.minute        \n",
    "    return df\n",
    "\n",
    "\n",
    "#Create new dummy dfs\n",
    "base_df = train.copy()\n",
    "base_weather = weather.copy()\n",
    "\n",
    "\n",
    "#Remove unnecessary columns\n",
    "base_df = base_df.drop('Unnamed: 0', axis=1)\n",
    "base_weather = base_weather.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n",
    "base_weather[\"localstrptime\"]= pd.to_datetime(base_weather[\"localstrptime\"])\n",
    "base_df['datetime_local'] = pd.to_datetime(base_df['datetime_local'])\n",
    "base_weather = base_weather.rename(columns={'localstrptime':'datetime_local'})\n",
    "\n",
    "#Add time columns.\n",
    "addtimecol(base_df, 'datetime_local')\n",
    "\n",
    "#Set index to datetime\n",
    "base_df.set_index('datetime_local', inplace=True)\n",
    "base_weather.set_index('datetime_local', inplace=True)\n",
    "\n",
    "#Concatenate the weather DataFrame to the base DataFrame\n",
    "base_df = pd.concat([base_df, base_weather], axis=1)\n",
    "\n",
    "# Drop all NaN values\n",
    "#base_df.dropna(subset=['demand_kW', 'Temperature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df = base_df.copy()\n",
    "\n",
    "dummy_df = dummy_df.reset_index()\n",
    "dummy_df = dummy_df.drop(['hour'], axis=1)\n",
    "dummy_df = dummy_df.drop(['datetime'], axis=1)\n",
    "dummy_df = dummy_df.drop(['datetime_local'], axis=1)\n",
    "dummy_df = dummy_df.drop(['datetime_UTC'], axis=1)\n",
    "dummy_normalized_df = dummy_df.copy()\n",
    "#Still drop demand_kW NaNs\n",
    "dummy_normalized_df = dummy_normalized_df.dropna(subset=['demand_kW'], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe Column preprocessing functions\n",
    "- Interpolate columns with missing values\n",
    "- Normalizing columns (Min-max Normalization)\n",
    "- One-hot encoding categorical columns\n",
    "\n",
    "Quite important to do it in that order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column(df, columnname):\n",
    "    \"\"\"Function which returns a Dataframe where the given column is normalized through min-max normalization.\"\"\"\n",
    "    df[f'{columnname}_normalized'] = (df[columnname] - df[columnname].min()) / (df[columnname].max() - df[columnname].min())\n",
    "    return df.drop([columnname], axis=1)\n",
    "\n",
    "def add_one_hot_encoder(df, colname):\n",
    "    \"\"\"\n",
    "    Function which returns a DataFrame where the given column has been removed and replaced by\n",
    "    one-hot-encoding columns for each value in the original column.\n",
    "    \"\"\"\n",
    "    onehot = pd.get_dummies(df[colname], prefix=colname)\n",
    "    return df.drop(colname, axis=1).join(onehot)\n",
    "\n",
    "def interpolate_column(df, colname):\n",
    "    df[f'{colname}_interpolated'] = df[colname].interpolate(method='linear')\n",
    "    return df.drop([colname], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolate = ['Temperature', 'Relative Humidity']\n",
    "to_normalize = ['Relative Humidity_interpolated', 'Temperature_interpolated']\n",
    "add_one_hot_encoding = ['weekday', 'year', 'month']\n",
    "\n",
    "\n",
    "for x in interpolate:\n",
    "    dummy_normalized_df = interpolate_column(dummy_normalized_df, x)\n",
    "for x in to_normalize:\n",
    "    dummy_normalized_df = normalize_column(dummy_normalized_df, x)\n",
    "for x in add_one_hot_encoding:\n",
    "    dummy_normalized_df = add_one_hot_encoder(dummy_normalized_df, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "\n",
    "First we build the skeleton:\n",
    "- Divide into train/test\n",
    "- Set target column\n",
    "- Get Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "\n",
    "#Define train, test sets\\n\",\n",
    "train, test = train_test_split(dummy_normalized_df, shuffle=True)\n",
    "X_train = train.copy().drop(['demand_kW'], axis=1)\n",
    "Y_train = train['demand_kW']\n",
    "X_test = test.copy().drop(['demand_kW'], axis=1)\n",
    "Y_test = test['demand_kW']\n",
    "\n",
    "def test_model(model, data, debug=False):\n",
    "    xtrain, ytrain, xtest, ytest = data\n",
    "    if debug:\n",
    "        print(\"Fitting model...\")\n",
    "    model.fit(xtrain, ytrain)\n",
    "    if debug:\n",
    "        print('Predicting...')\n",
    "    acc = model.predict(xtest)\n",
    "    if debug:\n",
    "        print('Calculating mean absolute error...')\n",
    "    return mean_absolute_error(list(ytest), acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Random Forest Regression\n",
    "# rfr = RandomForestRegressor(\n",
    "#     verbose=1,\n",
    "#     n_estimators=100\n",
    "#     )\n",
    "# rfr.fit(X_train, Y_train)\n",
    "# rfr_acc = rfr.predict(X_test)\n",
    "# print(r2_score(list(Y_test), rfr_acc))\n",
    "# print(mean_absolute_error(list(Y_test), rfr_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# knn = KNeighborsRegressor(n_neighbors=4)\n",
    "# knn.fit(X_train, Y_train)\n",
    "# knn_acc = knn.predict(X_test)\n",
    "# print(r2_score(list(Y_test), knn_acc))\n",
    "# print(mean_absolute_error(list(Y_test), knn_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featureImportance = rfr.feature_importances_\n",
    "# for x in range(len(featureImportance)):\n",
    "#     print(f'{dummy_normalized_df.columns[1:][x]} has a feature importance of: {featureImportance[x]}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From here, model testing. Delete at your own discretion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -Failed- /// SUCCESSFULL attempt to automate parameter search!\n",
    "Add all parameters you want to check into the dict below to see what the best combination is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.47547995272093\n"
     ]
    }
   ],
   "source": [
    "parameter_settings = {\n",
    "    'n_estimators': [10, 20, 50],\n",
    "    'criterion': ['squared_error', 'friedman_mse', 'poisson']#,\n",
    "    #'max_depth': [2, 4, 6],\n",
    "    #'min_samples_split': [2, 4, 8]\n",
    "}\n",
    "data = [X_train, Y_train, X_test, Y_test]\n",
    "model = RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model with parameters: {'n_estimators': 10, 'criterion': 'squared_error'}\n",
      "Fitting model...\n",
      "Predicting...\n",
      "Calculating mean absolute error...\n",
      "Mean Absolute Error = 102.86142692044685\n",
      "Time spent: 15.495572566986084 seconds. \n",
      "\n",
      "Testing model with parameters: {'n_estimators': 10, 'criterion': 'friedman_mse'}\n",
      "Fitting model...\n",
      "Predicting...\n",
      "Calculating mean absolute error...\n",
      "Mean Absolute Error = 102.56604595680301\n",
      "Time spent: 15.941078424453735 seconds. \n",
      "\n",
      "Testing model with parameters: {'n_estimators': 10, 'criterion': 'poisson'}\n",
      "Fitting model...\n",
      "Predicting...\n",
      "Calculating mean absolute error...\n",
      "Mean Absolute Error = 102.95391555404576\n",
      "Time spent: 18.838756799697876 seconds. \n",
      "\n",
      "Testing model with parameters: {'n_estimators': 20, 'criterion': 'squared_error'}\n",
      "Fitting model...\n",
      "Predicting...\n",
      "Calculating mean absolute error...\n",
      "Mean Absolute Error = 101.51565639709797\n",
      "Time spent: 27.55039882659912 seconds. \n",
      "\n",
      "Testing model with parameters: {'n_estimators': 20, 'criterion': 'friedman_mse'}\n",
      "Fitting model...\n",
      "Predicting...\n",
      "Calculating mean absolute error...\n",
      "Mean Absolute Error = 101.46939692994685\n",
      "Time spent: 31.56662893295288 seconds. \n",
      "\n",
      "Testing model with parameters: {'n_estimators': 20, 'criterion': 'poisson'}\n",
      "Fitting model...\n",
      "Predicting...\n",
      "Calculating mean absolute error...\n",
      "Mean Absolute Error = 101.7119281639997\n",
      "Time spent: 35.3441481590271 seconds. \n",
      "\n",
      "Testing model with parameters: {'n_estimators': 50, 'criterion': 'squared_error'}\n",
      "Fitting model...\n",
      "Predicting...\n",
      "Calculating mean absolute error...\n",
      "Mean Absolute Error = 100.64288624669018\n",
      "Time spent: 74.1656174659729 seconds. \n",
      "\n",
      "Testing model with parameters: {'n_estimators': 50, 'criterion': 'friedman_mse'}\n",
      "Fitting model...\n",
      "Predicting...\n",
      "Calculating mean absolute error...\n",
      "Mean Absolute Error = 100.75376390801475\n",
      "Time spent: 69.79285168647766 seconds. \n",
      "\n",
      "Testing model with parameters: {'n_estimators': 50, 'criterion': 'poisson'}\n",
      "Fitting model...\n",
      "Predicting...\n",
      "Calculating mean absolute error...\n",
      "Mean Absolute Error = 100.77474594355391\n",
      "Time spent: 77.5619740486145 seconds. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def model_optimizer(data, model, params):\n",
    "    parameter_combinations = itertools.product(*params.values())\n",
    "    results = {}\n",
    "    for parameters in parameter_combinations:\n",
    "        start = time.time()\n",
    "        params_dict = dict(zip(params.keys(), parameters))\n",
    "        print('Testing model with parameters: ' + str(params_dict))\n",
    "        current_model = model(**params_dict)\n",
    "        mae = test_model(current_model, data, debug = False)\n",
    "        print(f'Mean Absolute Error = {mae}')\n",
    "        modelname = str(params_dict)\n",
    "        end = time.time()\n",
    "        print(f'Time spent: {end-start} seconds. \\n')\n",
    "        results[modelname] = [mae, (end-start)]\n",
    "    return results\n",
    "        \n",
    "test = rf_optimizer(data, RandomForestRegressor, parameter_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting: {'n_estimators': 10, 'criterion': 'squared_error'}. \n",
      "MAE: 102.86142692044685. \n",
      "Time Spent: 15.495572566986084.\n",
      "\n",
      "Setting: {'n_estimators': 10, 'criterion': 'friedman_mse'}. \n",
      "MAE: 102.56604595680301. \n",
      "Time Spent: 15.941078424453735.\n",
      "\n",
      "Setting: {'n_estimators': 10, 'criterion': 'poisson'}. \n",
      "MAE: 102.95391555404576. \n",
      "Time Spent: 18.838756799697876.\n",
      "\n",
      "Setting: {'n_estimators': 20, 'criterion': 'squared_error'}. \n",
      "MAE: 101.51565639709797. \n",
      "Time Spent: 27.55039882659912.\n",
      "\n",
      "Setting: {'n_estimators': 20, 'criterion': 'friedman_mse'}. \n",
      "MAE: 101.46939692994685. \n",
      "Time Spent: 31.56662893295288.\n",
      "\n",
      "Setting: {'n_estimators': 20, 'criterion': 'poisson'}. \n",
      "MAE: 101.7119281639997. \n",
      "Time Spent: 35.3441481590271.\n",
      "\n",
      "Setting: {'n_estimators': 50, 'criterion': 'squared_error'}. \n",
      "MAE: 100.64288624669018. \n",
      "Time Spent: 74.1656174659729.\n",
      "\n",
      "Setting: {'n_estimators': 50, 'criterion': 'friedman_mse'}. \n",
      "MAE: 100.75376390801475. \n",
      "Time Spent: 69.79285168647766.\n",
      "\n",
      "Setting: {'n_estimators': 50, 'criterion': 'poisson'}. \n",
      "MAE: 100.77474594355391. \n",
      "Time Spent: 77.5619740486145.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for setting in test.keys():\n",
    "    print(f'Setting: {setting}. \\nMAE: {test[setting][0]}. \\nTime Spent: {test[setting][1]}.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
