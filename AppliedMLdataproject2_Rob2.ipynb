{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries and Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6GgydedI6kRr"
   },
   "outputs": [],
   "source": [
    "import math, datetime, time, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import math, datetime, time, random\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import tqdm\n",
    "\n",
    "def load_data(data_path):\n",
    "    data = pd.read_csv(data_path)  \n",
    "    return data\n",
    "\n",
    "inbound = load_data(\"inbound_loads.csv\")\n",
    "outbound = load_data(\"outbound_laods.csv\")\n",
    "weather = load_data(\"weather.csv\")\n",
    "#For loop to ensure that all pallet data is in the same dataframe\n",
    "pallet = load_data(\"Pallet_history_Gold_Spike[0].csv\")\n",
    "for x in range(1, 10):\n",
    "    pallet = pd.concat([pallet, load_data(f\"Pallet_history_Gold_Spike[{x}].csv\")])\n",
    "pallet = pallet.drop(['lot_code', \n",
    "                      'tran_type', \n",
    "                      'final_pallet_code', \n",
    "                      'warehouse_facility_id',\n",
    "                      'source_system_id'], axis=1)\n",
    "trainentest = load_data(\"demand_kWtrain_val.csv\")\n",
    "train = trainentest.iloc[:273988,:]\n",
    "test = trainentest.iloc[273988:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwIsOHLEjdRk"
   },
   "source": [
    "# Preprocessing the Data\n",
    "### 1. Load features and get them into the base dataframe\n",
    "\n",
    "- load all features into the base dataframe\n",
    "- create base_df\n",
    "\n",
    "### 2. Preprocessing of features\n",
    "- create dummy\n",
    "- normalization (DECISION: Min-Max Normalization) \n",
    "- one hot encoding\n",
    "- interpolating (fill in in between values)\n",
    "\n",
    "### 3. Cutting off the dataframe \n",
    "DECISION: ? \n",
    "Which datapoints to keep?\n",
    "Pallet_movement_5min starts 2nd of Jan 2019, so first rows is NaN. \n",
    "\n",
    "-  Demand values we have:\n",
    "12/31/2018  21:15:00  upandincluding 10/11/2021/ 6:07:00\n",
    "-  Predicting the demand from \n",
    "10/11/2021/ 6:08 upandincluding 12/13/2021  17:59:00 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load features and get them into the base dataframe\n",
    "#### Load features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total weight of pallets coming into the warehouse in the previous 1h, 5h, 10h, 23h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Incoming weight feature preprocessing\n",
    "#load all data\n",
    "incoming_weight_1h = load_data('incoming_weight_df_1h.csv')\n",
    "incoming_weight_5h = load_data('incoming_weight_df_5h.csv')\n",
    "incoming_weight_10h = load_data('incoming_weight_df_10h.csv')\n",
    "incoming_weight_23h = load_data('incoming_weight_df.csv')\n",
    "#rename columns \n",
    "incoming_weight_5h = incoming_weight_5h.rename(columns = {'weight_23h' : 'weight_5h'})\n",
    "incoming_weight_1h = incoming_weight_1h.rename(columns = {'weight_23h' : 'weight_1h'})\n",
    "incoming_weight_10h = incoming_weight_10h.rename(columns = {'weight_23h' : 'weight_10h'})\n",
    "#get them to a datetime object\n",
    "incoming_weight_1h['datetime_local'] = pd.to_datetime(incoming_weight_1h['datetime_local'])\n",
    "incoming_weight_5h['datetime_local'] = pd.to_datetime(incoming_weight_5h['datetime_local'])\n",
    "incoming_weight_10h['datetime_local'] = pd.to_datetime(incoming_weight_10h['datetime_local'])\n",
    "incoming_weight_23h['datetime_local'] = pd.to_datetime(incoming_weight_23h['datetime_local'])\n",
    "#set index to be datetime\n",
    "incoming_weight_1h.set_index('datetime_local', inplace=True)\n",
    "incoming_weight_5h.set_index('datetime_local', inplace=True)\n",
    "incoming_weight_10h.set_index('datetime_local', inplace=True)\n",
    "incoming_weight_23h.set_index('datetime_local', inplace=True)\n",
    "#reshape them to start at 2018-31-12 9:15PM\n",
    "incoming_weight_1h = incoming_weight_1h[2361:]\n",
    "incoming_weight_5h = incoming_weight_5h[2330:] \n",
    "incoming_weight_10h = incoming_weight_10h[2326:]\n",
    "incoming_weight_23h = incoming_weight_23h[2323:]\n",
    "#Drop duplicates\n",
    "incoming_weight_1h = incoming_weight_1h.loc[~incoming_weight_1h.index.duplicated()]\n",
    "incoming_weight_5h = incoming_weight_5h.loc[~incoming_weight_5h.index.duplicated()]\n",
    "incoming_weight_10h = incoming_weight_10h.loc[~incoming_weight_10h.index.duplicated()]\n",
    "incoming_weight_23h = incoming_weight_23h.loc[~incoming_weight_23h.index.duplicated()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of pallets moved within 5 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "pallet_move_5min = load_data('pallet_movement_5min_ft.csv')\n",
    "#rename column\n",
    "pallet_move_5min.rename(columns = {'quantity' : 'pallet_movement_5min'}, inplace = True)\n",
    "#make index a datetime object and set as index\n",
    "pallet_move_5min['datetime_local'] = pd.to_datetime(pallet_move_5min['datetime_local'])\n",
    "pallet_move_5min.set_index('datetime_local', inplace = True)\n",
    "#delete duplicates\n",
    "pallet_move_5min = pallet_move_5min.loc[~pallet_move_5min.index.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_door = load_data(\"feature_inbound_outbound_door_open.csv\")\n",
    "base_door = base_door.rename(columns = {'total' : 'doors_open'})\n",
    "base_door['datetime_local'] = pd.to_datetime(base_door['datetime_local'])\n",
    "base_door.set_index('datetime_local', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the base dataframe base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XXuGO5sMNXm8",
    "outputId": "976536a7-441f-4770-c483-43a2861db264"
   },
   "outputs": [],
   "source": [
    "def addtimecol(df, colname): ####input df and colname \n",
    "    df[colname] = pd.to_datetime(df[colname])         \n",
    "    df['year'] = df[colname].dt.year\n",
    "    df['month'] = df[colname].dt.month\n",
    "    df['weekday'] = df[colname].dt.weekday\n",
    "    df['day'] = df[colname].dt.day\n",
    "    df['hour'] = df[colname].dt.hour\n",
    "    df['minute'] = df[colname].dt.minute        \n",
    "    return df\n",
    "\n",
    "#Create new dummy dfs\n",
    "base_df = train.copy()\n",
    "base_weather = weather.copy()\n",
    "\n",
    "#Remove unnecessary columns\n",
    "base_df = base_df.drop('Unnamed: 0', axis=1)\n",
    "base_weather = base_weather.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n",
    "base_weather[\"localstrptime\"]= pd.to_datetime(base_weather[\"localstrptime\"])\n",
    "base_df['datetime_local'] = pd.to_datetime(base_df['datetime_local'])\n",
    "base_weather = base_weather.rename(columns={'localstrptime':'datetime_local'})\n",
    "\n",
    "#Add time columns.\n",
    "addtimecol(base_df, 'datetime_local')\n",
    "\n",
    "#Set index to datetime\n",
    "base_df.set_index('datetime_local', inplace=True)\n",
    "base_weather.set_index('datetime_local', inplace=True)\n",
    "\n",
    "#Concatenate the weather DataFrame to the base DataFrame\n",
    "base_df = pd.concat([base_df, base_weather], axis=1)\n",
    "\n",
    "#Concatenate the incoming weight dataframe with the base dataframe\n",
    "base_df = pd.concat([base_df, incoming_weight_1h], axis=1)\n",
    "base_df = pd.concat([base_df, incoming_weight_5h], axis=1)\n",
    "base_df = pd.concat([base_df, incoming_weight_10h], axis=1)\n",
    "base_df = pd.concat([base_df, incoming_weight_23h], axis=1)\n",
    "\n",
    "#Concatenate the pallet movement feature\n",
    "base_df = pd.concat([base_df, pallet_move_5min], axis = 1)\n",
    "\n",
    "#Concatenate the door feature\n",
    "base_df = pd.concat([base_df, base_door], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing of features\n",
    "\n",
    "#### Creating the dummy df with which we will do model selection\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['demand_kW', 'year', 'month', 'weekday', 'Relative Humidity',\n",
      "       'Temperature', 'weight_1h', 'weight_5h', 'weight_10h', 'weight_23h',\n",
      "       'pallet_movement_5min', 'doors_open'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "new_df = base_df.reindex(pd.date_range(start=base_df.index.min(),\n",
    "                                                  end=base_df.index.max(),\n",
    "                                                  freq='1min'))\n",
    "new_df = new_df.drop(['hour', 'day', 'datetime', 'datetime_UTC', 'minute'], axis=1)\n",
    "print(new_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column(df, columnname):\n",
    "    \"\"\"Function which returns a Dataframe where the given column is normalized through min-max normalization.\"\"\"\n",
    "    df[f'{columnname}_normalized'] = (df[columnname] - df[columnname].min()) / (df[columnname].max() - df[columnname].min())\n",
    "    return df.drop([columnname], axis=1)\n",
    "\n",
    "def add_one_hot_encoder(df, colname):\n",
    "    \"\"\"\n",
    "    Function which returns a DataFrame where the given column has been removed and replaced by\n",
    "    one-hot-encoding columns for each value in the original column.\n",
    "    \"\"\"\n",
    "    onehot = pd.get_dummies(df[colname], prefix=colname)\n",
    "    return df.drop(colname, axis=1).join(onehot)\n",
    "\n",
    "def interpolate_column(df, colname):\n",
    "    df[f'{colname}_interpolated'] = df[colname].interpolate(method='linear')\n",
    "    return df.drop([colname], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolate = ['Temperature', 'Relative Humidity', 'demand_kW']\n",
    "to_normalize = ['Relative Humidity_interpolated', 'Temperature_interpolated', 'weight_23h','weight_10h', 'weight_5h', 'weight_1h', 'pallet_movement_5min', 'doors_open']\n",
    "add_one_hot_encoding = ['weekday', 'year', 'month']\n",
    "\n",
    "\n",
    "for x in interpolate:\n",
    "    new_df = interpolate_column(new_df, x)\n",
    "for x in to_normalize:\n",
    "    new_df = normalize_column(new_df, x)\n",
    "for x in add_one_hot_encoding:\n",
    "    new_df = add_one_hot_encoder(new_df, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demand_kW_interpolated 195\n",
      "Relative Humidity_interpolated_normalized 0\n",
      "Temperature_interpolated_normalized 0\n",
      "weight_23h_normalized 10213\n",
      "weight_10h_normalized 10993\n",
      "weight_5h_normalized 11293\n",
      "weight_1h_normalized 11533\n",
      "pallet_movement_5min_normalized 1830\n",
      "doors_open_normalized 10993\n",
      "weekday_0.0 0\n",
      "weekday_1.0 0\n",
      "weekday_2.0 0\n",
      "weekday_3.0 0\n",
      "weekday_4.0 0\n",
      "weekday_5.0 0\n",
      "weekday_6.0 0\n",
      "year_2018.0 0\n",
      "year_2019.0 0\n",
      "year_2020.0 0\n",
      "year_2021.0 0\n",
      "month_1.0 0\n",
      "month_2.0 0\n",
      "month_3.0 0\n",
      "month_4.0 0\n",
      "month_5.0 0\n",
      "month_6.0 0\n",
      "month_7.0 0\n",
      "month_8.0 0\n",
      "month_9.0 0\n",
      "month_10.0 0\n",
      "month_11.0 0\n",
      "month_12.0 0\n"
     ]
    }
   ],
   "source": [
    "#dropping = ['day', 'datetime', 'datetime_UTC', 'minute']\n",
    "#for x in dropping:\n",
    "#    new_df = new_df.drop(x, axis=1)\n",
    "for x in new_df.columns:\n",
    "    print(x, new_df[x].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.rename(columns={'demand_kW_interpolated':'demand_kW'}, inplace=True)\n",
    "new_df = new_df.dropna(subset = ['demand_kW', 'weight_1h_normalized', 'doors_open_normalized', 'pallet_movement_5min_normalized'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demand_kW 0\n",
      "Relative Humidity_interpolated_normalized 0\n",
      "Temperature_interpolated_normalized 0\n",
      "weight_23h_normalized 0\n",
      "weight_10h_normalized 0\n",
      "weight_5h_normalized 0\n",
      "weight_1h_normalized 0\n",
      "pallet_movement_5min_normalized 0\n",
      "doors_open_normalized 0\n",
      "weekday_0.0 0\n",
      "weekday_1.0 0\n",
      "weekday_2.0 0\n",
      "weekday_3.0 0\n",
      "weekday_4.0 0\n",
      "weekday_5.0 0\n",
      "weekday_6.0 0\n",
      "year_2018.0 0\n",
      "year_2019.0 0\n",
      "year_2020.0 0\n",
      "year_2021.0 0\n",
      "month_1.0 0\n",
      "month_2.0 0\n",
      "month_3.0 0\n",
      "month_4.0 0\n",
      "month_5.0 0\n",
      "month_6.0 0\n",
      "month_7.0 0\n",
      "month_8.0 0\n",
      "month_9.0 0\n",
      "month_10.0 0\n",
      "month_11.0 0\n",
      "month_12.0 0\n"
     ]
    }
   ],
   "source": [
    "for x in new_df.columns:\n",
    "    print(x, new_df[x].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model Model 1 with parameters: {'n_estimators': 50}\n",
      "Starting fold 1\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 83.63793867996438. Test error: 349.2392588929855. Time taken: 0.3742563724517822 s.\n",
      "Starting fold 2\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 92.58098562620565. Test error: 274.5142568452369. Time taken: 0.48471665382385254 s.\n",
      "Starting fold 3\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 3 train error: 88.54572258114369. Test error: 322.4975184818255. Time taken: 0.5616903305053711 s.\n",
      "Starting fold 4\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 4 train error: 96.91485486103744. Test error: 308.0410768254591. Time taken: 0.5999970436096191 s.\n",
      "Starting fold 5\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 5 train error: 93.35846973895134. Test error: 304.25662271044075. Time taken: 0.6730859279632568 s.\n",
      "Starting fold 6\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 6 train error: 94.52577937666433. Test error: 391.8509437847363. Time taken: 0.729670524597168 s.\n",
      "Starting fold 7\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 7 train error: 98.28211334428804. Test error: 466.5120955353554. Time taken: 0.7752585411071777 s.\n",
      "Starting fold 8\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 8 train error: 100.23046438661844. Test error: 375.2059523676609. Time taken: 0.8424704074859619 s.\n",
      "Finished testing model. Test RMSE: 375.2059523676609. Time taken: 5.0411458015441895.\n",
      "Testing model Model 2 with parameters: {'n_estimators': 100}\n",
      "Starting fold 1\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 88.23290948093184. Test error: 349.20631958262743. Time taken: 0.7210993766784668 s.\n",
      "Starting fold 2\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 85.45623342653559. Test error: 284.2548740963803. Time taken: 0.9159972667694092 s.\n",
      "Starting fold 3\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 3 train error: 89.85940943704954. Test error: 324.3578854616435. Time taken: 1.0648117065429688 s.\n",
      "Starting fold 4\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 4 train error: 93.26117843175984. Test error: 307.2128649451158. Time taken: 1.1684207916259766 s.\n",
      "Starting fold 5\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 5 train error: 93.01586469210315. Test error: 308.47623702150577. Time taken: 1.297877311706543 s.\n",
      "Starting fold 6\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 6 train error: 92.32178179966427. Test error: 389.3083671843055. Time taken: 1.430450677871704 s.\n",
      "Starting fold 7\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 7 train error: 96.6607175648442. Test error: 464.4715538069145. Time taken: 1.4988417625427246 s.\n",
      "Starting fold 8\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 8 train error: 98.27243801517541. Test error: 375.92502658272247. Time taken: 1.6558985710144043 s.\n",
      "Finished testing model. Test RMSE: 375.92502658272247. Time taken: 9.753397464752197.\n",
      "Optimization completed. Best model is RandomForestRegressor(n_estimators=50) with parameters \n",
      "\n",
      " [{'n_estimators': 50}, [RandomForestRegressor(n_estimators=50), 375.2059523676609, [[83.63793867996438, 92.58098562620565, 88.54572258114369, 96.91485486103744, 93.35846973895134, 94.52577937666433, 98.28211334428804, 100.23046438661844], [349.2392588929855, 274.5142568452369, 322.4975184818255, 308.0410768254591, 304.25662271044075, 391.8509437847363, 466.5120955353554, 375.2059523676609]], [0.3742563724517822, 0.48471665382385254, 0.5616903305053711, 0.5999970436096191, 0.6730859279632568, 0.729670524597168, 0.7752585411071777, 0.8424704074859619]]]. \n",
      "\n",
      "    RMSE is 375.2059523676609.\n",
      "RMSE of best model does not improve on the best model of today. Not saving model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model 1': [{'n_estimators': 50},\n",
       "  [RandomForestRegressor(n_estimators=50),\n",
       "   375.2059523676609,\n",
       "   [[83.63793867996438,\n",
       "     92.58098562620565,\n",
       "     88.54572258114369,\n",
       "     96.91485486103744,\n",
       "     93.35846973895134,\n",
       "     94.52577937666433,\n",
       "     98.28211334428804,\n",
       "     100.23046438661844],\n",
       "    [349.2392588929855,\n",
       "     274.5142568452369,\n",
       "     322.4975184818255,\n",
       "     308.0410768254591,\n",
       "     304.25662271044075,\n",
       "     391.8509437847363,\n",
       "     466.5120955353554,\n",
       "     375.2059523676609]],\n",
       "   [0.3742563724517822,\n",
       "    0.48471665382385254,\n",
       "    0.5616903305053711,\n",
       "    0.5999970436096191,\n",
       "    0.6730859279632568,\n",
       "    0.729670524597168,\n",
       "    0.7752585411071777,\n",
       "    0.8424704074859619]]],\n",
       " 'Model 2': [{'n_estimators': 100},\n",
       "  [RandomForestRegressor(),\n",
       "   375.92502658272247,\n",
       "   [[88.23290948093184,\n",
       "     85.45623342653559,\n",
       "     89.85940943704954,\n",
       "     93.26117843175984,\n",
       "     93.01586469210315,\n",
       "     92.32178179966427,\n",
       "     96.6607175648442,\n",
       "     98.27243801517541],\n",
       "    [349.20631958262743,\n",
       "     284.2548740963803,\n",
       "     324.3578854616435,\n",
       "     307.2128649451158,\n",
       "     308.47623702150577,\n",
       "     389.3083671843055,\n",
       "     464.4715538069145,\n",
       "     375.92502658272247]],\n",
       "   [0.7210993766784668,\n",
       "    0.9159972667694092,\n",
       "    1.0648117065429688,\n",
       "    1.1684207916259766,\n",
       "    1.297877311706543,\n",
       "    1.430450677871704,\n",
       "    1.4988417625427246,\n",
       "    1.6558985710144043]]]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_settings = {\n",
    "    'n_estimators':[50, 100],\n",
    "}\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from model_features import find_optimal_parameters\n",
    "find_optimal_parameters(new_df, RandomForestRegressor, parameter_settings, n_splits=8, verbose=True, interval='1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model Model 1 with parameters: {'n_estimators': 50, 'criterion': 'squared_error', 'max_features': 'sqrt', 'bootstrap': True}\n",
      "Starting fold 1\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 20.488522790465144. Test error: 381.79617621699873. Time taken: 15.338068962097168 s.\n",
      "Starting fold 2\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 25.424888279178052. Test error: 270.22722964237437. Time taken: 34.12650537490845 s.\n",
      "Starting fold 3\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 3 train error: 23.72339889950992. Test error: 303.73251027002175. Time taken: 55.01563286781311 s.\n",
      "Starting fold 4\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 4 train error: 23.299293177051844. Test error: 280.76764617834516. Time taken: 72.48229193687439 s.\n",
      "Starting fold 5\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 5 train error: 23.885680495064687. Test error: 270.73699664901426. Time taken: 91.62823534011841 s.\n",
      "Starting fold 6\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 6 train error: 23.310543016281542. Test error: 390.410069473647. Time taken: 114.09598565101624 s.\n",
      "Starting fold 7\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 7 train error: 24.551269231614462. Test error: 641.8598595644586. Time taken: 129.63905000686646 s.\n",
      "Starting fold 8\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 8 train error: 30.033250663101853. Test error: 382.9773946804941. Time taken: 149.67999458312988 s.\n",
      "Finished testing model. Test RMSE: 382.9773946804941. Time taken: 662.0057647228241.\n",
      "Testing model Model 2 with parameters: {'n_estimators': 50, 'criterion': 'squared_error', 'max_features': 'sqrt', 'bootstrap': False}\n",
      "Starting fold 1\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 15.691611324454724. Test error: 376.34663583962123. Time taken: 18.853814601898193 s.\n",
      "Starting fold 2\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 20.17269023907662. Test error: 269.6513665493871. Time taken: 42.57264947891235 s.\n",
      "Starting fold 3\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 3 train error: 17.929832741176455. Test error: 304.2000479503726. Time taken: 68.19208431243896 s.\n",
      "Starting fold 4\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 4 train error: 17.088642275817822. Test error: 281.4737214014821. Time taken: 93.17430257797241 s.\n",
      "Starting fold 5\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 5 train error: 17.28275006765428. Test error: 271.54987110205445. Time taken: 116.71957731246948 s.\n",
      "Starting fold 6\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 6 train error: 16.59681292541442. Test error: 392.68323976720785. Time taken: 141.09454822540283 s.\n",
      "Starting fold 7\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 7 train error: 17.1985991499032. Test error: 656.2937487683346. Time taken: 166.12389397621155 s.\n",
      "Starting fold 8\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 8 train error: 22.145924273157714. Test error: 381.56514062503123. Time taken: 189.02765130996704 s.\n",
      "Finished testing model. Test RMSE: 381.56514062503123. Time taken: 835.7585217952728.\n",
      "Testing model Model 3 with parameters: {'n_estimators': 50, 'criterion': 'squared_error', 'max_features': 'log2', 'bootstrap': True}\n",
      "Starting fold 1\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 21.24540670736943. Test error: 382.98202319388747. Time taken: 14.534294843673706 s.\n",
      "Starting fold 2\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 26.702341955861495. Test error: 269.6696613131519. Time taken: 32.44933462142944 s.\n",
      "Starting fold 3\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 3 train error: 24.585237692254772. Test error: 302.3156581925733. Time taken: 51.44966530799866 s.\n",
      "Starting fold 4\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 4 train error: 24.327082430495654. Test error: 277.89805933016544. Time taken: 69.06448912620544 s.\n",
      "Starting fold 5\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 5 train error: 24.974406637720623. Test error: 272.41124534422875. Time taken: 87.27216100692749 s.\n",
      "Starting fold 6\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 6 train error: 24.21649917237403. Test error: 391.05094087383003. Time taken: 107.4266107082367 s.\n",
      "Starting fold 7\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 7 train error: 25.437642523159102. Test error: 646.0287751211728. Time taken: 125.38096070289612 s.\n",
      "Starting fold 8\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 8 train error: 30.78529861648745. Test error: 378.12682048823353. Time taken: 144.08741879463196 s.\n",
      "Finished testing model. Test RMSE: 378.12682048823353. Time taken: 631.6649351119995.\n",
      "Testing model Model 4 with parameters: {'n_estimators': 50, 'criterion': 'squared_error', 'max_features': 'log2', 'bootstrap': False}\n",
      "Starting fold 1\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 15.691277245069097. Test error: 385.32445686367515. Time taken: 18.4938063621521 s.\n",
      "Starting fold 2\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 20.172598107903223. Test error: 269.13728089751544. Time taken: 40.69980835914612 s.\n",
      "Starting fold 3\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 3 train error: 17.929258712531816. Test error: 302.95518648463366. Time taken: 63.986002683639526 s.\n",
      "Starting fold 4\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 4 train error: 17.089178220905577. Test error: 279.58356006572944. Time taken: 88.95030093193054 s.\n",
      "Starting fold 5\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 5 train error: 17.28273642617954. Test error: 271.87417403336366. Time taken: 109.82133483886719 s.\n",
      "Starting fold 6\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 6 train error: 16.597473378900258. Test error: 393.12384653492796. Time taken: 134.73857378959656 s.\n",
      "Starting fold 7\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 7 train error: 17.198823791892423. Test error: 649.1586725898082. Time taken: 156.0664291381836 s.\n",
      "Starting fold 8\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 8 train error: 22.146014189116467. Test error: 384.7301015585497. Time taken: 183.48122358322144 s.\n",
      "Finished testing model. Test RMSE: 384.7301015585497. Time taken: 796.2374796867371.\n",
      "Testing model Model 5 with parameters: {'n_estimators': 50, 'criterion': 'squared_error', 'max_features': None, 'bootstrap': True}\n",
      "Starting fold 1\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 17.966940452747103. Test error: 410.50092937562556. Time taken: 41.96032166481018 s.\n",
      "Starting fold 2\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 22.468855379167824. Test error: 291.9410147419383. Time taken: 91.39066171646118 s.\n",
      "Starting fold 3\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 3 train error: 20.452438106780477. Test error: 326.96467815053506. Time taken: 147.56659483909607 s.\n",
      "Starting fold 4\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 4 train error: 20.128069038213017. Test error: 315.6624756215057. Time taken: 207.6685185432434 s.\n",
      "Starting fold 5\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 5 train error: 20.34153900360323. Test error: 292.5913211473117. Time taken: 263.4786055088043 s.\n",
      "Starting fold 6\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 6 train error: 19.77541111650097. Test error: 414.82038821875926. Time taken: 322.064847946167 s.\n",
      "Starting fold 7\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 7 train error: 20.680416554362008. Test error: 487.95050364063104. Time taken: 380.9469621181488 s.\n",
      "Starting fold 8\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 8 train error: 27.273175913546595. Test error: 412.56806436919567. Time taken: 446.78158736228943 s.\n",
      "Finished testing model. Test RMSE: 412.56806436919567. Time taken: 1901.8580996990204.\n",
      "Testing model Model 6 with parameters: {'n_estimators': 50, 'criterion': 'squared_error', 'max_features': None, 'bootstrap': False}\n",
      "Starting fold 1\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 15.688099332181187. Test error: 446.4253710744787. Time taken: 52.82279014587402 s.\n",
      "Starting fold 2\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 20.169044691512806. Test error: 331.83355676076474. Time taken: 117.61808276176453 s.\n",
      "Starting fold 3\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 3 train error: 17.926399054429098. Test error: 379.03693604860865. Time taken: 189.40881824493408 s.\n",
      "Starting fold 4\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 4 train error: 17.085466820413195. Test error: 369.83944761399533. Time taken: 268.0347354412079 s.\n",
      "Starting fold 5\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 5 train error: 17.27979526382343. Test error: 349.02795813112385. Time taken: 344.54780769348145 s.\n",
      "Starting fold 6\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 6 train error: 16.593658023141852. Test error: 467.04805056757624. Time taken: 416.4694538116455 s.\n",
      "Starting fold 7\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 7 train error: 17.19548131421712. Test error: 573.540265838875. Time taken: 490.6070158481598 s.\n",
      "Starting fold 8\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 8 train error: 22.143685787438084. Test error: 486.8537739736833. Time taken: 574.3104040622711 s.\n",
      "Finished testing model. Test RMSE: 486.8537739736833. Time taken: 2453.8191080093384.\n",
      "Testing model Model 7 with parameters: {'n_estimators': 50, 'criterion': 'squared_error', 'max_features': 1.0, 'bootstrap': True}\n",
      "Starting fold 1\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 18.007533603644653. Test error: 412.20932018524064. Time taken: 41.90681719779968 s.\n",
      "Starting fold 2\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 22.453768969652643. Test error: 291.5212554532952. Time taken: 91.82575488090515 s.\n",
      "Starting fold 3\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 3 train error: 20.468038853989558. Test error: 326.5524116190237. Time taken: 147.16400957107544 s.\n",
      "Starting fold 4\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 4 train error: 20.101380270827914. Test error: 314.86054182671023. Time taken: 207.60428619384766 s.\n",
      "Starting fold 5\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 5 train error: 20.359532412319744. Test error: 293.6322751778934. Time taken: 264.45151829719543 s.\n",
      "Starting fold 6\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 6 train error: 19.796394041501962. Test error: 415.56740546724643. Time taken: 321.42017793655396 s.\n",
      "Starting fold 7\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 7 train error: 20.63264968883802. Test error: 493.14188785245943. Time taken: 380.2444152832031 s.\n",
      "Starting fold 8\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 8 train error: 27.332960664354676. Test error: 409.54693875026203. Time taken: 445.9002285003662 s.\n",
      "Finished testing model. Test RMSE: 409.54693875026203. Time taken: 1900.5172078609467.\n",
      "Testing model Model 8 with parameters: {'n_estimators': 50, 'criterion': 'squared_error', 'max_features': 1.0, 'bootstrap': False}\n",
      "Starting fold 1\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 15.688099332181187. Test error: 446.0625053359313. Time taken: 52.76032567024231 s.\n",
      "Starting fold 2\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 20.169044691512806. Test error: 331.87027921631255. Time taken: 118.425852060318 s.\n",
      "Starting fold 3\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 3 train error: 17.926399054429098. Test error: 378.83770896215816. Time taken: 189.1468210220337 s.\n",
      "Starting fold 4\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 4 train error: 17.085466820413195. Test error: 369.67432090445345. Time taken: 268.0357768535614 s.\n",
      "Starting fold 5\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 5 train error: 17.27979526382343. Test error: 348.57240972926326. Time taken: 345.6738498210907 s.\n",
      "Starting fold 6\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 6 train error: 16.593658023141852. Test error: 467.27397955744266. Time taken: 416.06537318229675 s.\n",
      "Starting fold 7\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 7 train error: 17.19548131421712. Test error: 573.5321443146642. Time taken: 492.42921900749207 s.\n",
      "Starting fold 8\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 8 train error: 22.143685787438084. Test error: 488.44013014787095. Time taken: 573.609368801117 s.\n",
      "Finished testing model. Test RMSE: 488.44013014787095. Time taken: 2456.146586418152.\n",
      "Testing model Model 9 with parameters: {'n_estimators': 50, 'criterion': 'friedman_mse', 'max_features': 'sqrt', 'bootstrap': True}\n",
      "Starting fold 1\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 20.391135413142962. Test error: 380.05130342969244. Time taken: 15.440808773040771 s.\n",
      "Starting fold 2\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 25.197224486000025. Test error: 271.7258442938433. Time taken: 34.35406970977783 s.\n",
      "Starting fold 3\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 3 train error: 23.534143636805872. Test error: 304.27206303490084. Time taken: 55.48802089691162 s.\n",
      "Starting fold 4\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 4 train error: 23.476810212780343. Test error: 280.15662553718016. Time taken: 75.1985011100769 s.\n",
      "Starting fold 5\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 5 train error: 23.93672124264368. Test error: 270.30722588034877. Time taken: 92.17530727386475 s.\n",
      "Starting fold 6\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 6 train error: 23.256943847867056. Test error: 392.13482233811305. Time taken: 114.24779844284058 s.\n",
      "Starting fold 7\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 7 train error: 24.46012152583388. Test error: 638.6073184689915. Time taken: 134.34630131721497 s.\n",
      "Starting fold 8\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 8 train error: 29.974964632014352. Test error: 382.43826974701176. Time taken: 151.10167121887207 s.\n",
      "Finished testing model. Test RMSE: 382.43826974701176. Time taken: 672.3524787425995.\n",
      "Testing model Model 10 with parameters: {'n_estimators': 50, 'criterion': 'friedman_mse', 'max_features': 'sqrt', 'bootstrap': False}\n",
      "Starting fold 1\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 15.688099332181187. Test error: 378.654236614927. Time taken: 19.098143100738525 s.\n",
      "Starting fold 2\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 20.169044691512806. Test error: 270.42776079177304. Time taken: 43.7604877948761 s.\n",
      "Starting fold 3\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 3 train error: 17.926399054429098. Test error: 303.81997239583046. Time taken: 68.20517706871033 s.\n",
      "Starting fold 4\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 4 train error: 17.085466820413195. Test error: 279.6675603293594. Time taken: 95.47054696083069 s.\n",
      "Starting fold 5\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 5 train error: 17.27979526382343. Test error: 271.8373817589285. Time taken: 117.83404326438904 s.\n",
      "Starting fold 6\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 6 train error: 16.593658023141852. Test error: 394.75497349129375. Time taken: 143.1532688140869 s.\n",
      "Starting fold 7\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 7 train error: 17.19548131421712. Test error: 670.9023169739257. Time taken: 165.20329642295837 s.\n",
      "Starting fold 8\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 8 train error: 22.143685787438084. Test error: 387.5310421844936. Time taken: 196.9184594154358 s.\n",
      "Finished testing model. Test RMSE: 387.5310421844936. Time taken: 849.6434228420258.\n",
      "Testing model Model 11 with parameters: {'n_estimators': 50, 'criterion': 'friedman_mse', 'max_features': 'log2', 'bootstrap': True}\n",
      "Starting fold 1\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 21.117264886940028. Test error: 385.68081669245566. Time taken: 14.883030891418457 s.\n",
      "Starting fold 2\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 26.310687470107837. Test error: 270.35376413054087. Time taken: 32.5676052570343 s.\n",
      "Starting fold 3\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 3 train error: 24.54057648727979. Test error: 303.4090493298207. Time taken: 51.77444338798523 s.\n",
      "Starting fold 4\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 4 train error: 24.218194189096465. Test error: 279.31423630854385. Time taken: 71.22980380058289 s.\n",
      "Starting fold 5\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 5 train error: 25.065470280759417. Test error: 272.2853036431068. Time taken: 87.9014184474945 s.\n",
      "Starting fold 6\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 6 train error: 24.265351305832645. Test error: 395.00194624219404. Time taken: 109.53647112846375 s.\n",
      "Starting fold 7\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 7 train error: 25.39009481962278. Test error: 641.2909914073988. Time taken: 125.554194688797 s.\n",
      "Starting fold 8\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 8 train error: 30.74252915192245. Test error: 382.3427496978261. Time taken: 143.32402348518372 s.\n",
      "Finished testing model. Test RMSE: 382.3427496978261. Time taken: 636.7709910869598.\n",
      "Testing model Model 12 with parameters: {'n_estimators': 50, 'criterion': 'friedman_mse', 'max_features': 'log2', 'bootstrap': False}\n",
      "Starting fold 1\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 15.688099332181187. Test error: 380.5958408572354. Time taken: 18.177911281585693 s.\n",
      "Starting fold 2\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 20.169044691512806. Test error: 270.6326190768641. Time taken: 41.48606753349304 s.\n",
      "Starting fold 3\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 3 train error: 17.926399054429098. Test error: 301.85598658740923. Time taken: 65.34135723114014 s.\n",
      "Starting fold 4\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 4 train error: 17.085466820413195. Test error: 278.88417694051543. Time taken: 90.93619871139526 s.\n",
      "Starting fold 5\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 5 train error: 17.27979526382343. Test error: 270.83153482327845. Time taken: 112.33442711830139 s.\n",
      "Starting fold 6\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 6 train error: 16.593658023141852. Test error: 395.1862167881627. Time taken: 134.80207467079163 s.\n",
      "Starting fold 7\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 7 train error: 17.19548131421712. Test error: 678.2801105164796. Time taken: 156.26701879501343 s.\n",
      "Starting fold 8\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 8 train error: 22.143685787438084. Test error: 386.2862569894444. Time taken: 181.81245684623718 s.\n",
      "Finished testing model. Test RMSE: 386.2862569894444. Time taken: 801.1575121879578.\n",
      "Testing model Model 13 with parameters: {'n_estimators': 50, 'criterion': 'friedman_mse', 'max_features': None, 'bootstrap': True}\n",
      "Starting fold 1\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 18.004441741696347. Test error: 408.35031417282954. Time taken: 42.06232714653015 s.\n",
      "Starting fold 2\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 22.46264958163514. Test error: 292.0290161663056. Time taken: 91.15161347389221 s.\n",
      "Starting fold 3\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 3 train error: 20.444285807528043. Test error: 327.3860080016147. Time taken: 147.53281617164612 s.\n",
      "Starting fold 4\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 4 train error: 20.17033098481726. Test error: 316.63718715909476. Time taken: 207.40958166122437 s.\n",
      "Starting fold 5\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 5 train error: 20.3851645234743. Test error: 292.48929956362286. Time taken: 263.27067613601685 s.\n",
      "Starting fold 6\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 6 train error: 19.75873186739953. Test error: 414.08959703181523. Time taken: 322.0835132598877 s.\n",
      "Starting fold 7\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 7 train error: 20.585428204898314. Test error: 490.68335155963763. Time taken: 380.93381094932556 s.\n",
      "Starting fold 8\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 8 train error: 27.266847714243916. Test error: 409.7871460437321. Time taken: 470.9601263999939 s.\n",
      "Finished testing model. Test RMSE: 409.7871460437321. Time taken: 1925.4044651985168.\n",
      "Testing model Model 14 with parameters: {'n_estimators': 50, 'criterion': 'friedman_mse', 'max_features': None, 'bootstrap': False}\n",
      "Starting fold 1\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 15.688099332181187. Test error: 447.84746050194224. Time taken: 55.2127890586853 s.\n",
      "Starting fold 2\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 20.169044691512806. Test error: 331.8081205524494. Time taken: 122.89901208877563 s.\n",
      "Starting fold 3\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 3 train error: 17.926399054429098. Test error: 381.0258690066266. Time taken: 200.01531505584717 s.\n",
      "Starting fold 4\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 4 train error: 17.085466820413195. Test error: 372.7793796118169. Time taken: 276.94905853271484 s.\n",
      "Starting fold 5\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 5 train error: 17.27979526382343. Test error: 350.86705131782264. Time taken: 368.2141318321228 s.\n",
      "Starting fold 6\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 6 train error: 16.593658023141852. Test error: 468.8054641462275. Time taken: 445.25641655921936 s.\n",
      "Starting fold 7\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 7 train error: 17.19548131421712. Test error: 576.6712767017865. Time taken: 514.9609105587006 s.\n",
      "Starting fold 8\n",
      "Training model...\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "could not allocate 234881024 bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfind_optimal_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1min\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRandomForestRegressor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameter_settings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Universiteit\\AML\\AppliedMachineLearning\\model_features.py:71\u001b[0m, in \u001b[0;36mfind_optimal_parameters\u001b[1;34m(data, model, params, n_splits, verbose, pickle_best)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTesting model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams_dict\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     70\u001b[0m current_model \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams_dict)\n\u001b[1;32m---> 71\u001b[0m results[model_name]\u001b[38;5;241m.\u001b[39mappend(\u001b[43mrun_timeseries_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     72\u001b[0m total_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(results[model_name][\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinished testing model. Test RMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[model_name][\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Time taken: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\Universiteit\\AML\\AppliedMachineLearning\\model_features.py:127\u001b[0m, in \u001b[0;36mrun_timeseries_model\u001b[1;34m(data, model, n_splits, verbose)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 127\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicting...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    462\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    465\u001b[0m ]\n\u001b[0;32m    467\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 473\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:186\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    184\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\tree\\_classes.py:1247\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \n\u001b[0;32m   1221\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1247\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32msklearn\\tree\\_tree.pyx:147\u001b[0m, in \u001b[0;36msklearn.tree._tree.DepthFirstTreeBuilder.build\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msklearn\\tree\\_tree.pyx:242\u001b[0m, in \u001b[0;36msklearn.tree._tree.DepthFirstTreeBuilder.build\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msklearn\\tree\\_tree.pyx:748\u001b[0m, in \u001b[0;36msklearn.tree._tree.Tree._add_node\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msklearn\\tree\\_tree.pyx:719\u001b[0m, in \u001b[0;36msklearn.tree._tree.Tree._resize_c\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msklearn\\tree\\_utils.pyx:35\u001b[0m, in \u001b[0;36msklearn.tree._utils.safe_realloc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: could not allocate 234881024 bytes"
     ]
    }
   ],
   "source": [
    "find_optimal_parameters(new_df.resample('1min').last(), RandomForestRegressor, parameter_settings, n_splits=8, verbose=True, interval='1day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model Model 1 with parameters: {'n_estimators': 50, 'criterion': 'squared_error', 'max_features': 'sqrt', 'bootstrap': True}\n",
      "Starting fold 1\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 45.53043886516663. Test error: 379.48154081712784. Time taken: 1.7515175342559814 s.\n",
      "Starting fold 2\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 55.023914826066466. Test error: 267.74548547056645. Time taken: 3.7848827838897705 s.\n",
      "Starting fold 3\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 3 train error: 56.74621675348395. Test error: 302.9841354421069. Time taken: 5.7350664138793945 s.\n",
      "Starting fold 4\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 4 train error: 57.799018321010074. Test error: 277.25957912967255. Time taken: 7.898113012313843 s.\n",
      "Starting fold 5\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 5 train error: 59.84074116671278. Test error: 270.0539156114416. Time taken: 9.743985176086426 s.\n",
      "Starting fold 6\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 6 train error: 59.86610338452403. Test error: 393.89122938280525. Time taken: 11.972455739974976 s.\n",
      "Starting fold 7\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 7 train error: 63.69914497833014. Test error: 465.5386090153677. Time taken: 13.790938377380371 s.\n",
      "Starting fold 8\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 8 train error: 66.04223025122519. Test error: 357.4409153891872. Time taken: 16.531235933303833 s.\n",
      "Finished testing model. Test RMSE: 357.4409153891872. Time taken: 71.2081949710846.\n",
      "Testing model Model 2 with parameters: {'n_estimators': 50, 'criterion': 'squared_error', 'max_features': 'sqrt', 'bootstrap': False}\n",
      "Starting fold 1\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 14.396986689787868. Test error: 387.48045827309534. Time taken: 2.0654349327087402 s.\n",
      "Starting fold 2\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 19.265618623980856. Test error: 269.4511311232416. Time taken: 4.502957582473755 s.\n",
      "Starting fold 3\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 3 train error: 17.02578217353627. Test error: 303.2776984634679. Time taken: 7.033963680267334 s.\n",
      "Starting fold 4\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 4 train error: 16.263645873482357. Test error: 278.8600126451226. Time taken: 9.542783975601196 s.\n",
      "Starting fold 5\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 5 train error: 16.464742614458448. Test error: 269.3904254142794. Time taken: 12.045031070709229 s.\n",
      "Starting fold 6\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 6 train error: 15.657246443443384. Test error: 393.4117776184927. Time taken: 14.47323203086853 s.\n",
      "Starting fold 7\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 7 train error: 16.265431652247795. Test error: 466.6958051785094. Time taken: 16.849761962890625 s.\n",
      "Starting fold 8\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 8 train error: 18.830693749420934. Test error: 354.7508305708045. Time taken: 20.489213228225708 s.\n",
      "Finished testing model. Test RMSE: 354.7508305708045. Time taken: 87.00237846374512.\n",
      "Testing model Model 3 with parameters: {'n_estimators': 50, 'criterion': 'squared_error', 'max_features': 'log2', 'bootstrap': True}\n",
      "Starting fold 1\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 47.11514984455147. Test error: 387.95388438601486. Time taken: 1.6165058612823486 s.\n",
      "Starting fold 2\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 56.050294584778726. Test error: 267.77026793185354. Time taken: 3.5499815940856934 s.\n",
      "Starting fold 3\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 3 train error: 57.73845604869546. Test error: 304.3760274824535. Time taken: 5.43884539604187 s.\n",
      "Starting fold 4\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 4 train error: 59.301315339640574. Test error: 275.53020150964363. Time taken: 7.4893879890441895 s.\n",
      "Starting fold 5\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 5 train error: 61.90674169495444. Test error: 272.5522793258088. Time taken: 9.275163888931274 s.\n",
      "Starting fold 6\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 6 train error: 61.10602005773467. Test error: 392.20008348181096. Time taken: 11.184972524642944 s.\n",
      "Starting fold 7\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 7 train error: 64.86838016178136. Test error: 468.2131706635572. Time taken: 12.94662356376648 s.\n",
      "Starting fold 8\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 8 train error: 68.01634805667027. Test error: 354.4946601586752. Time taken: 15.303415536880493 s.\n",
      "Finished testing model. Test RMSE: 354.4946601586752. Time taken: 66.8048963546753.\n",
      "Testing model Model 4 with parameters: {'n_estimators': 50, 'criterion': 'squared_error', 'max_features': 'log2', 'bootstrap': False}\n",
      "Starting fold 1\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 14.396983943715137. Test error: 388.31615437181813. Time taken: 1.9603230953216553 s.\n",
      "Starting fold 2\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 19.265618702892073. Test error: 267.88111680806566. Time taken: 4.199431657791138 s.\n",
      "Starting fold 3\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 3 train error: 17.025781878139952. Test error: 304.58260844297445. Time taken: 6.664470911026001 s.\n",
      "Starting fold 4\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 4 train error: 16.26368245317013. Test error: 276.66087353597806. Time taken: 9.02787160873413 s.\n",
      "Starting fold 5\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 5 train error: 16.464743096247005. Test error: 273.99767771990656. Time taken: 11.42535948753357 s.\n",
      "Starting fold 6\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 6 train error: 15.65724595993553. Test error: 394.7157266990881. Time taken: 13.804853677749634 s.\n",
      "Starting fold 7\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 7 train error: 16.26543184795952. Test error: 467.6687243326448. Time taken: 15.77197265625 s.\n",
      "Starting fold 8\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 8 train error: 18.83069403678624. Test error: 355.57218917209826. Time taken: 18.806004285812378 s.\n",
      "Finished testing model. Test RMSE: 355.57218917209826. Time taken: 81.6602873802185.\n",
      "Testing model Model 5 with parameters: {'n_estimators': 50, 'criterion': 'squared_error', 'max_features': None, 'bootstrap': True}\n",
      "Starting fold 1\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 39.029872762122615. Test error: 380.55622548856985. Time taken: 5.367033243179321 s.\n",
      "Starting fold 2\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 45.90216414620667. Test error: 279.04538203592244. Time taken: 11.355548858642578 s.\n",
      "Starting fold 3\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 3 train error: 46.48663226163529. Test error: 315.09340664591497. Time taken: 17.977354526519775 s.\n",
      "Starting fold 4\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 4 train error: 49.49857705776445. Test error: 299.217988110153. Time taken: 24.92656421661377 s.\n",
      "Starting fold 5\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 5 train error: 51.0503798667154. Test error: 276.6476062869028. Time taken: 31.18101668357849 s.\n",
      "Starting fold 6\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 6 train error: 50.19565295158476. Test error: 408.9608778874308. Time taken: 37.55190134048462 s.\n",
      "Starting fold 7\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 7 train error: 53.63152992016837. Test error: 460.3148670411919. Time taken: 44.160582304000854 s.\n",
      "Starting fold 8\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 8 train error: 58.188139503876705. Test error: 389.1943057785684. Time taken: 52.49733209609985 s.\n",
      "Finished testing model. Test RMSE: 389.1943057785684. Time taken: 225.01733326911926.\n",
      "Testing model Model 6 with parameters: {'n_estimators': 50, 'criterion': 'squared_error', 'max_features': None, 'bootstrap': False}\n",
      "Starting fold 1\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 14.39698346645346. Test error: 445.57692911412363. Time taken: 6.161038160324097 s.\n",
      "Starting fold 2\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 19.265618585085473. Test error: 332.1936337522017. Time taken: 13.0621018409729 s.\n",
      "Starting fold 3\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 3 train error: 17.02578113583015. Test error: 375.8641023364494. Time taken: 20.79527974128723 s.\n",
      "Starting fold 4\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 4 train error: 16.263643474921416. Test error: 369.85806523902835. Time taken: 28.88032341003418 s.\n",
      "Starting fold 5\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 5 train error: 16.46474217463298. Test error: 352.8938219175656. Time taken: 36.91594195365906 s.\n",
      "Starting fold 6\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 6 train error: 15.657245311260095. Test error: 467.94799874357824. Time taken: 43.94933009147644 s.\n",
      "Starting fold 7\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 7 train error: 16.265431184930396. Test error: 515.0547164607108. Time taken: 51.90018892288208 s.\n",
      "Starting fold 8\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 8 train error: 18.83069325408428. Test error: 458.6799428372592. Time taken: 62.31499624252319 s.\n",
      "Finished testing model. Test RMSE: 458.6799428372592. Time taken: 263.9792003631592.\n",
      "Testing model Model 7 with parameters: {'n_estimators': 50, 'criterion': 'squared_error', 'max_features': 1.0, 'bootstrap': True}\n",
      "Starting fold 1\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 39.471473913610495. Test error: 383.61305504555355. Time taken: 5.312683343887329 s.\n",
      "Starting fold 2\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 45.90817149371639. Test error: 279.2296086538681. Time taken: 11.410211086273193 s.\n",
      "Starting fold 3\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 3 train error: 46.85215415634634. Test error: 315.82099192889814. Time taken: 17.83767080307007 s.\n",
      "Starting fold 4\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 4 train error: 49.831768603421004. Test error: 298.97312586293395. Time taken: 25.2241792678833 s.\n",
      "Starting fold 5\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 5 train error: 51.34608909776853. Test error: 276.4878657634117. Time taken: 31.599599361419678 s.\n",
      "Starting fold 6\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 6 train error: 50.123572717200176. Test error: 404.4206586325815. Time taken: 37.71123766899109 s.\n",
      "Starting fold 7\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 7 train error: 53.7071039446657. Test error: 459.48839229580625. Time taken: 45.30664420127869 s.\n",
      "Starting fold 8\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 8 train error: 58.135153212345855. Test error: 389.4368872210481. Time taken: 53.715252161026 s.\n",
      "Finished testing model. Test RMSE: 389.4368872210481. Time taken: 228.11747789382935.\n",
      "Testing model Model 8 with parameters: {'n_estimators': 50, 'criterion': 'squared_error', 'max_features': 1.0, 'bootstrap': False}\n",
      "Starting fold 1\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 14.39698346645346. Test error: 446.981788970568. Time taken: 6.269989490509033 s.\n",
      "Starting fold 2\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 19.265618585085473. Test error: 331.99207432510104. Time taken: 13.237809658050537 s.\n",
      "Starting fold 3\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 3 train error: 17.02578113583015. Test error: 375.56627754015943. Time taken: 21.096484184265137 s.\n",
      "Starting fold 4\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 4 train error: 16.263643474921416. Test error: 369.87508294449475. Time taken: 29.550341844558716 s.\n",
      "Starting fold 5\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 5 train error: 16.46474217463298. Test error: 352.9235411773492. Time taken: 37.68070316314697 s.\n",
      "Starting fold 6\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 6 train error: 15.657245311260095. Test error: 467.86593599592527. Time taken: 44.74863147735596 s.\n",
      "Starting fold 7\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 7 train error: 16.265431184930396. Test error: 515.0876958314078. Time taken: 52.92477369308472 s.\n",
      "Starting fold 8\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 8 train error: 18.83069325408428. Test error: 458.0993320373865. Time taken: 63.24574685096741 s.\n",
      "Finished testing model. Test RMSE: 458.0993320373865. Time taken: 268.7544803619385.\n",
      "Testing model Model 9 with parameters: {'n_estimators': 50, 'criterion': 'friedman_mse', 'max_features': 'sqrt', 'bootstrap': True}\n",
      "Starting fold 1\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 45.708564911333696. Test error: 387.9073309455542. Time taken: 1.7657725811004639 s.\n",
      "Starting fold 2\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 55.96443590840986. Test error: 269.22612019750113. Time taken: 3.805769205093384 s.\n",
      "Starting fold 3\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 3 train error: 55.303479339461546. Test error: 302.0528296174571. Time taken: 5.8455116748809814 s.\n",
      "Starting fold 4\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 4 train error: 58.282428568285596. Test error: 276.46794555120596. Time taken: 7.9515955448150635 s.\n",
      "Starting fold 5\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 5 train error: 59.94852990312192. Test error: 270.9504343226566. Time taken: 9.988911390304565 s.\n",
      "Starting fold 6\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 6 train error: 59.706980485891286. Test error: 389.78014276122235. Time taken: 12.039397478103638 s.\n",
      "Starting fold 7\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 7 train error: 63.72284789580416. Test error: 463.9050079272159. Time taken: 14.131735563278198 s.\n",
      "Starting fold 8\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 8 train error: 65.88257064069263. Test error: 357.40526240010576. Time taken: 16.91506338119507 s.\n",
      "Finished testing model. Test RMSE: 357.40526240010576. Time taken: 72.44375681877136.\n",
      "Testing model Model 10 with parameters: {'n_estimators': 50, 'criterion': 'friedman_mse', 'max_features': 'sqrt', 'bootstrap': False}\n",
      "Starting fold 1\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 14.39698346645346. Test error: 378.4225407517296. Time taken: 2.1268277168273926 s.\n",
      "Starting fold 2\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 19.265618585085473. Test error: 268.4366494106874. Time taken: 4.678491115570068 s.\n",
      "Starting fold 3\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 3 train error: 17.02578113583015. Test error: 302.9939071103073. Time taken: 7.119082927703857 s.\n",
      "Starting fold 4\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 4 train error: 16.263643474921416. Test error: 278.606098945918. Time taken: 9.746038675308228 s.\n",
      "Starting fold 5\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 5 train error: 16.46474217463298. Test error: 271.0597856470041. Time taken: 12.142912149429321 s.\n",
      "Starting fold 6\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 6 train error: 15.657245311260095. Test error: 395.516841610215. Time taken: 14.610788822174072 s.\n",
      "Starting fold 7\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 7 train error: 16.265431184930396. Test error: 463.9260877710725. Time taken: 17.04475975036621 s.\n",
      "Starting fold 8\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 8 train error: 18.83069325408428. Test error: 355.52836437123165. Time taken: 20.385133266448975 s.\n",
      "Finished testing model. Test RMSE: 355.52836437123165. Time taken: 87.85403442382812.\n",
      "Testing model Model 11 with parameters: {'n_estimators': 50, 'criterion': 'friedman_mse', 'max_features': 'log2', 'bootstrap': True}\n",
      "Starting fold 1\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 46.33557833625459. Test error: 383.1182240695649. Time taken: 1.6781833171844482 s.\n",
      "Starting fold 2\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 56.31250276872187. Test error: 269.49234552757633. Time taken: 3.623054265975952 s.\n",
      "Starting fold 3\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 3 train error: 57.410741087640794. Test error: 305.717437548388. Time taken: 5.636945009231567 s.\n",
      "Starting fold 4\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 4 train error: 60.244472167393205. Test error: 274.16256922952465. Time taken: 7.789003133773804 s.\n",
      "Starting fold 5\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 5 train error: 61.89166040704494. Test error: 274.720762139347. Time taken: 9.583736181259155 s.\n",
      "Starting fold 6\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 6 train error: 60.802017092146926. Test error: 392.49511416438463. Time taken: 11.378081321716309 s.\n",
      "Starting fold 7\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 7 train error: 65.47375031963495. Test error: 466.47759192464076. Time taken: 13.312211751937866 s.\n",
      "Starting fold 8\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 8 train error: 67.5055332592435. Test error: 355.2867828460426. Time taken: 16.45377492904663 s.\n",
      "Finished testing model. Test RMSE: 355.2867828460426. Time taken: 69.45498991012573.\n",
      "Testing model Model 12 with parameters: {'n_estimators': 50, 'criterion': 'friedman_mse', 'max_features': 'log2', 'bootstrap': False}\n",
      "Starting fold 1\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 14.39698346645346. Test error: 379.86029935192244. Time taken: 2.041245222091675 s.\n",
      "Starting fold 2\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 19.265618585085473. Test error: 268.3888799353421. Time taken: 4.444594383239746 s.\n",
      "Starting fold 3\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 3 train error: 17.02578113583015. Test error: 305.691230120943. Time taken: 6.825083255767822 s.\n",
      "Starting fold 4\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 4 train error: 16.263643474921416. Test error: 275.7100521823544. Time taken: 9.456967115402222 s.\n",
      "Starting fold 5\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 5 train error: 16.46474217463298. Test error: 272.7786235452766. Time taken: 11.73265290260315 s.\n",
      "Starting fold 6\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 6 train error: 15.657245311260095. Test error: 392.76706407074147. Time taken: 14.163390398025513 s.\n",
      "Starting fold 7\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 7 train error: 16.265431184930396. Test error: 464.9378020807205. Time taken: 16.228522777557373 s.\n",
      "Starting fold 8\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 8 train error: 18.83069325408428. Test error: 355.68957944103516. Time taken: 19.317264795303345 s.\n",
      "Finished testing model. Test RMSE: 355.68957944103516. Time taken: 84.20972084999084.\n",
      "Testing model Model 13 with parameters: {'n_estimators': 50, 'criterion': 'friedman_mse', 'max_features': None, 'bootstrap': True}\n",
      "Starting fold 1\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 38.957248530956655. Test error: 383.4703144528754. Time taken: 5.372343301773071 s.\n",
      "Starting fold 2\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 46.20002734649605. Test error: 277.9050344140853. Time taken: 11.477732181549072 s.\n",
      "Starting fold 3\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 3 train error: 46.61152943329502. Test error: 314.6270447961964. Time taken: 18.15278649330139 s.\n",
      "Starting fold 4\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 4 train error: 49.980938699682135. Test error: 299.9455129067993. Time taken: 25.372884035110474 s.\n",
      "Starting fold 5\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 5 train error: 51.249143825236345. Test error: 275.4970224157409. Time taken: 31.687395095825195 s.\n",
      "Starting fold 6\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 6 train error: 50.278779977245804. Test error: 403.70662961201236. Time taken: 38.05838656425476 s.\n",
      "Starting fold 7\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 7 train error: 53.69939713055338. Test error: 459.45741441938907. Time taken: 44.817111015319824 s.\n",
      "Starting fold 8\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 8 train error: 58.205525478005434. Test error: 393.72135938632897. Time taken: 53.81081581115723 s.\n",
      "Finished testing model. Test RMSE: 393.72135938632897. Time taken: 228.74945449829102.\n",
      "Testing model Model 14 with parameters: {'n_estimators': 50, 'criterion': 'friedman_mse', 'max_features': None, 'bootstrap': False}\n",
      "Starting fold 1\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 14.39698346645346. Test error: 452.9334200959374. Time taken: 6.32072901725769 s.\n",
      "Starting fold 2\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 19.265618585085473. Test error: 331.14247437575295. Time taken: 13.362656116485596 s.\n",
      "Starting fold 3\n",
      "Training model...\n",
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 3 train error: 17.02578113583015. Test error: 377.16944691302075. Time taken: 21.34746026992798 s.\n",
      "Starting fold 4\n",
      "Training model...\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "could not allocate 14680064 bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfind_optimal_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m10min\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRandomForestRegressor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameter_settings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Universiteit\\AML\\AppliedMachineLearning\\model_features.py:71\u001b[0m, in \u001b[0;36mfind_optimal_parameters\u001b[1;34m(data, model, params, n_splits, verbose, pickle_best)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTesting model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams_dict\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     70\u001b[0m current_model \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams_dict)\n\u001b[1;32m---> 71\u001b[0m results[model_name]\u001b[38;5;241m.\u001b[39mappend(\u001b[43mrun_timeseries_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     72\u001b[0m total_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(results[model_name][\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFinished testing model. Test RMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[model_name][\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Time taken: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\Universiteit\\AML\\AppliedMachineLearning\\model_features.py:127\u001b[0m, in \u001b[0;36mrun_timeseries_model\u001b[1;34m(data, model, n_splits, verbose)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 127\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicting...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    462\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    465\u001b[0m ]\n\u001b[0;32m    467\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 473\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:186\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    184\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\tree\\_classes.py:1247\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \n\u001b[0;32m   1221\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1247\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32msklearn\\tree\\_tree.pyx:147\u001b[0m, in \u001b[0;36msklearn.tree._tree.DepthFirstTreeBuilder.build\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msklearn\\tree\\_tree.pyx:242\u001b[0m, in \u001b[0;36msklearn.tree._tree.DepthFirstTreeBuilder.build\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msklearn\\tree\\_tree.pyx:748\u001b[0m, in \u001b[0;36msklearn.tree._tree.Tree._add_node\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msklearn\\tree\\_tree.pyx:719\u001b[0m, in \u001b[0;36msklearn.tree._tree.Tree._resize_c\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msklearn\\tree\\_utils.pyx:35\u001b[0m, in \u001b[0;36msklearn.tree._utils.safe_realloc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: could not allocate 14680064 bytes"
     ]
    }
   ],
   "source": [
    "find_optimal_parameters(new_df.resample('10min').last(), RandomForestRegressor, parameter_settings, n_splits=8, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fin_optimal_parameters(dummy_normalized_df, RandomForestRegressor, parameter_settings, n_splits=2, verbose=True)\n",
    "from model_features import find_optimal_parameters\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "parameter_settings = {\n",
    "    'activation' : ['relu', 'tanh']\n",
    "}\n",
    "\n",
    "find_optimal_parameters(new_df, MLPRegressor, parameter_settings, n_splits=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "id": "5etBuOV3mniN",
    "outputId": "2346b0ac-3201-4761-8ba4-9e5f8c15be50"
   },
   "outputs": [],
   "source": [
    "dummy_df = base_df.copy()\n",
    "#dummy_df = dummy_df.reset_index()\n",
    "dummy_df = dummy_df.drop(['hour'], axis=1)\n",
    "dummy_df = dummy_df.drop(['datetime'], axis=1)\n",
    "dummy_df = dummy_df.drop(['datetime_local'], axis=1)\n",
    "dummy_df = dummy_df.drop(['datetime_UTC'], axis=1)\n",
    "dummy_df\n",
    "\n",
    "dummy_normalized_df = dummy_df.copy()\n",
    "#Still drop demand_kW NaNs\n",
    "dummy_normalized_df = dummy_normalized_df.dropna(subset=['demand_kW'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1592126"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_df.pallet_movement_5min.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing functions defined\n",
    "DECISION: MinMax Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### interpolate/one-hot-encoding/normalizing\n",
    "DECISION: ?  normalization of the doors_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolate = ['Temperature', 'Relative Humidity', 'demand_kW']\n",
    "to_normalize = ['Relative Humidity_interpolated', 'Temperature_interpolated', 'weight_23h','weight_10h', 'weight_5h', 'weight_1h', 'pallet_movement_5min', 'doors_open']\n",
    "add_one_hot_encoding = ['weekday', 'year', 'month']\n",
    "\n",
    "\n",
    "for x in interpolate:\n",
    "    dummy_normalized_df = interpolate_column(dummy_normalized_df, x)\n",
    "for x in to_normalize:\n",
    "    dummy_normalized_df = normalize_column(dummy_normalized_df, x)\n",
    "for x in add_one_hot_encoding:\n",
    "    dummy_normalized_df = add_one_hot_encoder(dummy_normalized_df, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273879"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_normalized_df.pallet_movement_5min_normalized.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_normalized_df = dummy_normalized_df.dropna(subset = ['pallet_movement_5min_normalized'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Model selection and building\n",
    "## 1. Importing model libraries\n",
    "\n",
    "## 2. Divide Train and Test data\n",
    "\n",
    "## 3. Test models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dividing train & test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### dummy_normalized_df['pallet_movement_5min'] drop NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Testing functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_settings = {\n",
    "    'n_estimators': [20],\n",
    "    'criterion': ['squared_error', 'friedman_mse', 'squared_error', 'poisson'],\n",
    "    #'max_depth': [2, 4, 6],\n",
    "    #'min_samples_split': [2, 4, 8]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def model_optimizer(data, model, params, splits, verbose=False):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    parameter_combinations = itertools.product(*params.values())\n",
    "    results = {}\n",
    "    for parameters in parameter_combinations:\n",
    "        start = time.time()\n",
    "        params_dict = dict(zip(params.keys(), parameters))\n",
    "        print('Testing model with parameters: ' + str(params_dict))\n",
    "        current_model = model(**params_dict)\n",
    "        mae, model = test_model(current_model, data, debug = False)\n",
    "        print(f'Mean Absolute Error = {mae}')\n",
    "        modelname = str(params_dict)\n",
    "        end = time.time()\n",
    "        print(f'Time spent: {end-start} seconds. \\n')\n",
    "        results[modelname] = [mae, (end-start), model]\n",
    "    return results\n",
    "        \n",
    "#test = model_optimizer(data, RandomForestRegressor, parameter_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to help with model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import time\n",
    "\n",
    "def run_timeseries_model(data, model, n_splits = 5, verbose=False):\n",
    "    \"\"\"\n",
    "    Function which receives a data and a model as input.\n",
    "    Can also receive the amount of splits you want as input.\n",
    "    For debugging purposes, set verbose to True.\n",
    "    \n",
    "    Outputs a list of:\n",
    "        - The resulting model\n",
    "        - The final RMSE\n",
    "        - A list of the resulting Train RMSEs (per fold)\n",
    "        - A list of the resulting Test RMSEs (per fold)\n",
    "    \"\"\"\n",
    "    \n",
    "    ts = TimeSeriesSplit(n_splits=n_splits)\n",
    "    count = 1\n",
    "    train_rmses = []\n",
    "    test_rmses = []\n",
    "    for train, test in ts.split(data):\n",
    "        if verbose:\n",
    "            print(f'Starting fold {count}')\n",
    "        cv_train, cv_test = data.iloc[train], data.iloc[test]\n",
    "        y_train = cv_train['demand_kW']\n",
    "        x_train = cv_train.drop(['demand_kW'], axis=1)\n",
    "        y_test = cv_test['demand_kW']\n",
    "        x_test = cv_test.drop(['demand_kW'], axis=1)\n",
    "        train_start = time.time()\n",
    "        if verbose:\n",
    "            print(\"Training model...\")\n",
    "        model.fit(x_train, y_train)\n",
    "        train_stop = time.time()\n",
    "        \n",
    "        predict_start = time.time()\n",
    "        if verbose:\n",
    "            print(\"Predicting...\")\n",
    "        y_pred_test = model.predict(x_test)\n",
    "        y_pred_train = model.predict(x_train)\n",
    "        predict_stop = time.time()\n",
    "        \n",
    "        rmse_start = time.time()\n",
    "        if verbose:\n",
    "            print(\"Calculating rmse's...\")\n",
    "        train_rmse = mean_squared_error(y_train, y_pred_train, squared=False)\n",
    "        test_rmse = mean_squared_error(y_test, y_pred_test, squared=False)\n",
    "        rmse_stop = time.time()\n",
    "        \n",
    "        train_rmses.append(train_rmse)\n",
    "        test_rmses.append(test_rmse)\n",
    "        timings = [(train_stop - train_start), (predict_stop - predict_start), (rmse_stop - rmse_start), (rmse_stop - train_start)]\n",
    "        if verbose:\n",
    "            print(f'Fold {count} train error: {train_rmse}. Test error: {test_rmse}. Time taken: {timings[3]} s.')\n",
    "        count += 1\n",
    "    all_rmses = [train_rmses, test_rmses]\n",
    "    return [model, test_rmse, all_rmses, timings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pickle\n",
    "\n",
    "def find_optimal_parameters(data, model, params, n_splits=5, verbose=False):\n",
    "    \"\"\"\n",
    "    Function which will find the optimal parameters within set boudaries.\n",
    "    Receives as input:\n",
    "    - The data\n",
    "    - A model\n",
    "    - The dictionary of parameters to optimize:\n",
    "        - Key: parameter name\n",
    "        - Value: List of testing parameter values.\n",
    "    - The amount of Timeseries splits for crossvalidation (Standard: 5)\n",
    "    - Whether information should be printed or not (Standard: False)\n",
    "    \"\"\"\n",
    "    \n",
    "    parameter_combinations = itertools.product(*params.values())\n",
    "    results = {}\n",
    "    count = 1\n",
    "    for x in parameter_combinations:\n",
    "        model_name = f'Model {count}'\n",
    "        results[model_name] = [dict(zip(params.keys(), x))]\n",
    "        count +=1\n",
    "    lowest = 1000000000\n",
    "    best_model = \"\"\n",
    "    print(results['Model 1'])\n",
    "    for model_name in results.keys():\n",
    "        params_dict = results[model_name][0]\n",
    "        print(f'Testing model {model_name} with parameters: {params_dict}')\n",
    "        current_model = model(**params_dict)\n",
    "        results[model_name].append(run_timeseries_model(data, current_model, n_splits=n_splits, verbose=verbose))\n",
    "        print(results[model_name])\n",
    "        print(f'Finished testing model. Test RMSE: {results[model_name][1][1]}. Time taken: {results[model_name][1][3][3]}.')\n",
    "        if results[model_name][1][1] < lowest:\n",
    "            lowest = results[model_name][1][1]\n",
    "            best_model = model_name\n",
    "    print(f\"Optimization completed. Best model is {best_model} with parameters {results[model_name]}. \\n RMSE is {results[model_name][1][1]}.\")\n",
    "    pickle.dump(best_model, open(\"Best_model.pkl\", 'wb'))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model Model 1 with parameters: {'activation': 'relu'}\n",
      "Starting fold 1\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rob Pennekamp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 240.6029551160752. Test error: 308.79148242069664. Time taken: 450.47525000572205 s.\n",
      "Starting fold 2\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rob Pennekamp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 248.19592757147984. Test error: 495.5155389244764. Time taken: 918.9606564044952 s.\n",
      "Finished testing model. Test RMSE: 495.5155389244764. Time taken: 1369.4359064102173.\n",
      "Testing model Model 2 with parameters: {'activation': 'tanh'}\n",
      "Starting fold 1\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rob Pennekamp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 1 train error: 219.2418440030109. Test error: 293.1655512748899. Time taken: 548.3995881080627 s.\n",
      "Starting fold 2\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rob Pennekamp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting...\n",
      "Calculating rmse's...\n",
      "Fold 2 train error: 230.40526142255104. Test error: 389.4801666143394. Time taken: 1287.4136629104614 s.\n",
      "Finished testing model. Test RMSE: 389.4801666143394. Time taken: 1835.8132510185242.\n",
      "Optimization completed. Best model is MLPRegressor(activation='tanh') with parameters \n",
      "\n",
      " [{'activation': 'tanh'}, [MLPRegressor(activation='tanh'), 389.4801666143394, [[219.2418440030109, 230.40526142255104], [293.1655512748899, 389.4801666143394]], [548.3995881080627, 1287.4136629104614]]]. \n",
      "\n",
      "    RMSE is 389.4801666143394.\n",
      "New best rmse reached! Pickling model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rob Pennekamp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 0.24.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\Rob Pennekamp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator RandomForestRegressor from version 0.24.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Model 1': [{'activation': 'relu'},\n",
       "  [MLPRegressor(),\n",
       "   495.5155389244764,\n",
       "   [[240.6029551160752, 248.19592757147984],\n",
       "    [308.79148242069664, 495.5155389244764]],\n",
       "   [450.47525000572205, 918.9606564044952]]],\n",
       " 'Model 2': [{'activation': 'tanh'},\n",
       "  [MLPRegressor(activation='tanh'),\n",
       "   389.4801666143394,\n",
       "   [[219.2418440030109, 230.40526142255104],\n",
       "    [293.1655512748899, 389.4801666143394]],\n",
       "   [548.3995881080627, 1287.4136629104614]]]}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing DF Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_kW</th>\n",
       "      <th>day</th>\n",
       "      <th>minute</th>\n",
       "      <th>Relative Humidity_interpolated_normalized</th>\n",
       "      <th>Temperature_interpolated_normalized</th>\n",
       "      <th>weight_23h_normalized</th>\n",
       "      <th>weight_10h_normalized</th>\n",
       "      <th>weight_5h_normalized</th>\n",
       "      <th>weight_1h_normalized</th>\n",
       "      <th>pallet_movement_5min_normalized</th>\n",
       "      <th>...</th>\n",
       "      <th>month_3.0</th>\n",
       "      <th>month_4.0</th>\n",
       "      <th>month_5.0</th>\n",
       "      <th>month_6.0</th>\n",
       "      <th>month_7.0</th>\n",
       "      <th>month_8.0</th>\n",
       "      <th>month_9.0</th>\n",
       "      <th>month_10.0</th>\n",
       "      <th>month_11.0</th>\n",
       "      <th>month_12.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime_local</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-12-31 21:15:00</th>\n",
       "      <td>2064.101392</td>\n",
       "      <td>31.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.572375</td>\n",
       "      <td>0.442623</td>\n",
       "      <td>0.082728</td>\n",
       "      <td>0.110131</td>\n",
       "      <td>0.107216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 21:30:00</th>\n",
       "      <td>1874.002081</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.572375</td>\n",
       "      <td>0.442623</td>\n",
       "      <td>0.082728</td>\n",
       "      <td>0.110131</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 21:45:00</th>\n",
       "      <td>1988.168511</td>\n",
       "      <td>31.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.620183</td>\n",
       "      <td>0.426230</td>\n",
       "      <td>0.082728</td>\n",
       "      <td>0.109795</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 22:00:00</th>\n",
       "      <td>2022.795943</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.620183</td>\n",
       "      <td>0.426230</td>\n",
       "      <td>0.082728</td>\n",
       "      <td>0.109795</td>\n",
       "      <td>0.047662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 22:15:00</th>\n",
       "      <td>1986.981872</td>\n",
       "      <td>31.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.620183</td>\n",
       "      <td>0.426230</td>\n",
       "      <td>0.082728</td>\n",
       "      <td>0.109795</td>\n",
       "      <td>0.047662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-11 06:03:00</th>\n",
       "      <td>2217.847000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.864746</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.371198</td>\n",
       "      <td>0.190632</td>\n",
       "      <td>0.152500</td>\n",
       "      <td>0.015004</td>\n",
       "      <td>0.101205</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-11 06:04:00</th>\n",
       "      <td>2184.012000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.864746</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.371198</td>\n",
       "      <td>0.190632</td>\n",
       "      <td>0.152500</td>\n",
       "      <td>0.015004</td>\n",
       "      <td>0.094917</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-11 06:05:00</th>\n",
       "      <td>2159.482000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.864746</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.361868</td>\n",
       "      <td>0.190632</td>\n",
       "      <td>0.145594</td>\n",
       "      <td>0.015004</td>\n",
       "      <td>0.094618</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-11 06:06:00</th>\n",
       "      <td>2145.155000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.864746</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.361868</td>\n",
       "      <td>0.190632</td>\n",
       "      <td>0.126848</td>\n",
       "      <td>0.015004</td>\n",
       "      <td>0.092222</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-11 06:07:00</th>\n",
       "      <td>2213.599000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.864746</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.361868</td>\n",
       "      <td>0.190632</td>\n",
       "      <td>0.126848</td>\n",
       "      <td>0.015004</td>\n",
       "      <td>0.087731</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>273988 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       demand_kW   day  minute  \\\n",
       "datetime_local                                   \n",
       "2018-12-31 21:15:00  2064.101392  31.0    15.0   \n",
       "2018-12-31 21:30:00  1874.002081  31.0    30.0   \n",
       "2018-12-31 21:45:00  1988.168511  31.0    45.0   \n",
       "2018-12-31 22:00:00  2022.795943  31.0     0.0   \n",
       "2018-12-31 22:15:00  1986.981872  31.0    15.0   \n",
       "...                          ...   ...     ...   \n",
       "2021-10-11 06:03:00  2217.847000  11.0     3.0   \n",
       "2021-10-11 06:04:00  2184.012000  11.0     4.0   \n",
       "2021-10-11 06:05:00  2159.482000  11.0     5.0   \n",
       "2021-10-11 06:06:00  2145.155000  11.0     6.0   \n",
       "2021-10-11 06:07:00  2213.599000  11.0     7.0   \n",
       "\n",
       "                     Relative Humidity_interpolated_normalized  \\\n",
       "datetime_local                                                   \n",
       "2018-12-31 21:15:00                                   0.572375   \n",
       "2018-12-31 21:30:00                                   0.572375   \n",
       "2018-12-31 21:45:00                                   0.620183   \n",
       "2018-12-31 22:00:00                                   0.620183   \n",
       "2018-12-31 22:15:00                                   0.620183   \n",
       "...                                                        ...   \n",
       "2021-10-11 06:03:00                                   0.864746   \n",
       "2021-10-11 06:04:00                                   0.864746   \n",
       "2021-10-11 06:05:00                                   0.864746   \n",
       "2021-10-11 06:06:00                                   0.864746   \n",
       "2021-10-11 06:07:00                                   0.864746   \n",
       "\n",
       "                     Temperature_interpolated_normalized  \\\n",
       "datetime_local                                             \n",
       "2018-12-31 21:15:00                             0.442623   \n",
       "2018-12-31 21:30:00                             0.442623   \n",
       "2018-12-31 21:45:00                             0.426230   \n",
       "2018-12-31 22:00:00                             0.426230   \n",
       "2018-12-31 22:15:00                             0.426230   \n",
       "...                                                  ...   \n",
       "2021-10-11 06:03:00                             0.540984   \n",
       "2021-10-11 06:04:00                             0.540984   \n",
       "2021-10-11 06:05:00                             0.540984   \n",
       "2021-10-11 06:06:00                             0.540984   \n",
       "2021-10-11 06:07:00                             0.540984   \n",
       "\n",
       "                     weight_23h_normalized  weight_10h_normalized  \\\n",
       "datetime_local                                                      \n",
       "2018-12-31 21:15:00               0.082728               0.110131   \n",
       "2018-12-31 21:30:00               0.082728               0.110131   \n",
       "2018-12-31 21:45:00               0.082728               0.109795   \n",
       "2018-12-31 22:00:00               0.082728               0.109795   \n",
       "2018-12-31 22:15:00               0.082728               0.109795   \n",
       "...                                    ...                    ...   \n",
       "2021-10-11 06:03:00               0.371198               0.190632   \n",
       "2021-10-11 06:04:00               0.371198               0.190632   \n",
       "2021-10-11 06:05:00               0.361868               0.190632   \n",
       "2021-10-11 06:06:00               0.361868               0.190632   \n",
       "2021-10-11 06:07:00               0.361868               0.190632   \n",
       "\n",
       "                     weight_5h_normalized  weight_1h_normalized  \\\n",
       "datetime_local                                                    \n",
       "2018-12-31 21:15:00              0.107216              0.000000   \n",
       "2018-12-31 21:30:00              0.068400              0.000000   \n",
       "2018-12-31 21:45:00              0.068400              0.000000   \n",
       "2018-12-31 22:00:00              0.047662              0.000000   \n",
       "2018-12-31 22:15:00              0.047662              0.000000   \n",
       "...                                   ...                   ...   \n",
       "2021-10-11 06:03:00              0.152500              0.015004   \n",
       "2021-10-11 06:04:00              0.152500              0.015004   \n",
       "2021-10-11 06:05:00              0.145594              0.015004   \n",
       "2021-10-11 06:06:00              0.126848              0.015004   \n",
       "2021-10-11 06:07:00              0.126848              0.015004   \n",
       "\n",
       "                     pallet_movement_5min_normalized  ...  month_3.0  \\\n",
       "datetime_local                                        ...              \n",
       "2018-12-31 21:15:00                              NaN  ...          0   \n",
       "2018-12-31 21:30:00                              NaN  ...          0   \n",
       "2018-12-31 21:45:00                              NaN  ...          0   \n",
       "2018-12-31 22:00:00                              NaN  ...          0   \n",
       "2018-12-31 22:15:00                              NaN  ...          0   \n",
       "...                                              ...  ...        ...   \n",
       "2021-10-11 06:03:00                         0.101205  ...          0   \n",
       "2021-10-11 06:04:00                         0.094917  ...          0   \n",
       "2021-10-11 06:05:00                         0.094618  ...          0   \n",
       "2021-10-11 06:06:00                         0.092222  ...          0   \n",
       "2021-10-11 06:07:00                         0.087731  ...          0   \n",
       "\n",
       "                     month_4.0  month_5.0  month_6.0  month_7.0  month_8.0  \\\n",
       "datetime_local                                                               \n",
       "2018-12-31 21:15:00          0          0          0          0          0   \n",
       "2018-12-31 21:30:00          0          0          0          0          0   \n",
       "2018-12-31 21:45:00          0          0          0          0          0   \n",
       "2018-12-31 22:00:00          0          0          0          0          0   \n",
       "2018-12-31 22:15:00          0          0          0          0          0   \n",
       "...                        ...        ...        ...        ...        ...   \n",
       "2021-10-11 06:03:00          0          0          0          0          0   \n",
       "2021-10-11 06:04:00          0          0          0          0          0   \n",
       "2021-10-11 06:05:00          0          0          0          0          0   \n",
       "2021-10-11 06:06:00          0          0          0          0          0   \n",
       "2021-10-11 06:07:00          0          0          0          0          0   \n",
       "\n",
       "                     month_9.0  month_10.0  month_11.0  month_12.0  \n",
       "datetime_local                                                      \n",
       "2018-12-31 21:15:00          0           0           0           1  \n",
       "2018-12-31 21:30:00          0           0           0           1  \n",
       "2018-12-31 21:45:00          0           0           0           1  \n",
       "2018-12-31 22:00:00          0           0           0           1  \n",
       "2018-12-31 22:15:00          0           0           0           1  \n",
       "...                        ...         ...         ...         ...  \n",
       "2021-10-11 06:03:00          0           1           0           0  \n",
       "2021-10-11 06:04:00          0           1           0           0  \n",
       "2021-10-11 06:05:00          0           1           0           0  \n",
       "2021-10-11 06:06:00          0           1           0           0  \n",
       "2021-10-11 06:07:00          0           1           0           0  \n",
       "\n",
       "[273988 rows x 34 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1 = dummy_normalized_df[dummy_normalized_df[]].copy()\n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_kW</th>\n",
       "      <th>day</th>\n",
       "      <th>minute</th>\n",
       "      <th>Relative Humidity_interpolated_normalized</th>\n",
       "      <th>Temperature_interpolated_normalized</th>\n",
       "      <th>weight_23h_normalized</th>\n",
       "      <th>weight_10h_normalized</th>\n",
       "      <th>weight_5h_normalized</th>\n",
       "      <th>weight_1h_normalized</th>\n",
       "      <th>pallet_movement_5min_normalized</th>\n",
       "      <th>...</th>\n",
       "      <th>month_3.0</th>\n",
       "      <th>month_4.0</th>\n",
       "      <th>month_5.0</th>\n",
       "      <th>month_6.0</th>\n",
       "      <th>month_7.0</th>\n",
       "      <th>month_8.0</th>\n",
       "      <th>month_9.0</th>\n",
       "      <th>month_10.0</th>\n",
       "      <th>month_11.0</th>\n",
       "      <th>month_12.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime_local</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-12-31 21:15:00</th>\n",
       "      <td>2064.101392</td>\n",
       "      <td>31.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.572375</td>\n",
       "      <td>0.442623</td>\n",
       "      <td>0.082728</td>\n",
       "      <td>0.110131</td>\n",
       "      <td>0.107216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 21:30:00</th>\n",
       "      <td>1874.002081</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.572375</td>\n",
       "      <td>0.442623</td>\n",
       "      <td>0.082728</td>\n",
       "      <td>0.110131</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 21:45:00</th>\n",
       "      <td>1988.168511</td>\n",
       "      <td>31.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.620183</td>\n",
       "      <td>0.426230</td>\n",
       "      <td>0.082728</td>\n",
       "      <td>0.109795</td>\n",
       "      <td>0.068400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 22:00:00</th>\n",
       "      <td>2022.795943</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.620183</td>\n",
       "      <td>0.426230</td>\n",
       "      <td>0.082728</td>\n",
       "      <td>0.109795</td>\n",
       "      <td>0.047662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 22:15:00</th>\n",
       "      <td>1986.981872</td>\n",
       "      <td>31.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.620183</td>\n",
       "      <td>0.426230</td>\n",
       "      <td>0.082728</td>\n",
       "      <td>0.109795</td>\n",
       "      <td>0.047662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-11 05:00:00</th>\n",
       "      <td>2164.534000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.864746</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.363871</td>\n",
       "      <td>0.180877</td>\n",
       "      <td>0.159336</td>\n",
       "      <td>0.078976</td>\n",
       "      <td>0.031514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-11 05:15:00</th>\n",
       "      <td>2215.498000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.864746</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.371198</td>\n",
       "      <td>0.190632</td>\n",
       "      <td>0.171300</td>\n",
       "      <td>0.048270</td>\n",
       "      <td>0.113407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-11 05:30:00</th>\n",
       "      <td>1978.980000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.804240</td>\n",
       "      <td>0.557377</td>\n",
       "      <td>0.371198</td>\n",
       "      <td>0.190632</td>\n",
       "      <td>0.152500</td>\n",
       "      <td>0.015004</td>\n",
       "      <td>0.054271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-11 05:45:00</th>\n",
       "      <td>2249.147000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.864746</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.371198</td>\n",
       "      <td>0.190632</td>\n",
       "      <td>0.152500</td>\n",
       "      <td>0.015004</td>\n",
       "      <td>0.124935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-11 06:00:00</th>\n",
       "      <td>2213.599000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.864746</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.361868</td>\n",
       "      <td>0.190632</td>\n",
       "      <td>0.126848</td>\n",
       "      <td>0.015004</td>\n",
       "      <td>0.087731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97380 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       demand_kW   day  minute  \\\n",
       "datetime_local                                   \n",
       "2018-12-31 21:15:00  2064.101392  31.0    15.0   \n",
       "2018-12-31 21:30:00  1874.002081  31.0    30.0   \n",
       "2018-12-31 21:45:00  1988.168511  31.0    45.0   \n",
       "2018-12-31 22:00:00  2022.795943  31.0     0.0   \n",
       "2018-12-31 22:15:00  1986.981872  31.0    15.0   \n",
       "...                          ...   ...     ...   \n",
       "2021-10-11 05:00:00  2164.534000  11.0    14.0   \n",
       "2021-10-11 05:15:00  2215.498000  11.0    29.0   \n",
       "2021-10-11 05:30:00  1978.980000  11.0    44.0   \n",
       "2021-10-11 05:45:00  2249.147000  11.0    59.0   \n",
       "2021-10-11 06:00:00  2213.599000  11.0     7.0   \n",
       "\n",
       "                     Relative Humidity_interpolated_normalized  \\\n",
       "datetime_local                                                   \n",
       "2018-12-31 21:15:00                                   0.572375   \n",
       "2018-12-31 21:30:00                                   0.572375   \n",
       "2018-12-31 21:45:00                                   0.620183   \n",
       "2018-12-31 22:00:00                                   0.620183   \n",
       "2018-12-31 22:15:00                                   0.620183   \n",
       "...                                                        ...   \n",
       "2021-10-11 05:00:00                                   0.864746   \n",
       "2021-10-11 05:15:00                                   0.864746   \n",
       "2021-10-11 05:30:00                                   0.804240   \n",
       "2021-10-11 05:45:00                                   0.864746   \n",
       "2021-10-11 06:00:00                                   0.864746   \n",
       "\n",
       "                     Temperature_interpolated_normalized  \\\n",
       "datetime_local                                             \n",
       "2018-12-31 21:15:00                             0.442623   \n",
       "2018-12-31 21:30:00                             0.442623   \n",
       "2018-12-31 21:45:00                             0.426230   \n",
       "2018-12-31 22:00:00                             0.426230   \n",
       "2018-12-31 22:15:00                             0.426230   \n",
       "...                                                  ...   \n",
       "2021-10-11 05:00:00                             0.540984   \n",
       "2021-10-11 05:15:00                             0.540984   \n",
       "2021-10-11 05:30:00                             0.557377   \n",
       "2021-10-11 05:45:00                             0.540984   \n",
       "2021-10-11 06:00:00                             0.540984   \n",
       "\n",
       "                     weight_23h_normalized  weight_10h_normalized  \\\n",
       "datetime_local                                                      \n",
       "2018-12-31 21:15:00               0.082728               0.110131   \n",
       "2018-12-31 21:30:00               0.082728               0.110131   \n",
       "2018-12-31 21:45:00               0.082728               0.109795   \n",
       "2018-12-31 22:00:00               0.082728               0.109795   \n",
       "2018-12-31 22:15:00               0.082728               0.109795   \n",
       "...                                    ...                    ...   \n",
       "2021-10-11 05:00:00               0.363871               0.180877   \n",
       "2021-10-11 05:15:00               0.371198               0.190632   \n",
       "2021-10-11 05:30:00               0.371198               0.190632   \n",
       "2021-10-11 05:45:00               0.371198               0.190632   \n",
       "2021-10-11 06:00:00               0.361868               0.190632   \n",
       "\n",
       "                     weight_5h_normalized  weight_1h_normalized  \\\n",
       "datetime_local                                                    \n",
       "2018-12-31 21:15:00              0.107216              0.000000   \n",
       "2018-12-31 21:30:00              0.068400              0.000000   \n",
       "2018-12-31 21:45:00              0.068400              0.000000   \n",
       "2018-12-31 22:00:00              0.047662              0.000000   \n",
       "2018-12-31 22:15:00              0.047662              0.000000   \n",
       "...                                   ...                   ...   \n",
       "2021-10-11 05:00:00              0.159336              0.078976   \n",
       "2021-10-11 05:15:00              0.171300              0.048270   \n",
       "2021-10-11 05:30:00              0.152500              0.015004   \n",
       "2021-10-11 05:45:00              0.152500              0.015004   \n",
       "2021-10-11 06:00:00              0.126848              0.015004   \n",
       "\n",
       "                     pallet_movement_5min_normalized  ...  month_3.0  \\\n",
       "datetime_local                                        ...              \n",
       "2018-12-31 21:15:00                              NaN  ...        0.0   \n",
       "2018-12-31 21:30:00                              NaN  ...        0.0   \n",
       "2018-12-31 21:45:00                              NaN  ...        0.0   \n",
       "2018-12-31 22:00:00                              NaN  ...        0.0   \n",
       "2018-12-31 22:15:00                              NaN  ...        0.0   \n",
       "...                                              ...  ...        ...   \n",
       "2021-10-11 05:00:00                         0.031514  ...        0.0   \n",
       "2021-10-11 05:15:00                         0.113407  ...        0.0   \n",
       "2021-10-11 05:30:00                         0.054271  ...        0.0   \n",
       "2021-10-11 05:45:00                         0.124935  ...        0.0   \n",
       "2021-10-11 06:00:00                         0.087731  ...        0.0   \n",
       "\n",
       "                     month_4.0  month_5.0  month_6.0  month_7.0  month_8.0  \\\n",
       "datetime_local                                                               \n",
       "2018-12-31 21:15:00        0.0        0.0        0.0        0.0        0.0   \n",
       "2018-12-31 21:30:00        0.0        0.0        0.0        0.0        0.0   \n",
       "2018-12-31 21:45:00        0.0        0.0        0.0        0.0        0.0   \n",
       "2018-12-31 22:00:00        0.0        0.0        0.0        0.0        0.0   \n",
       "2018-12-31 22:15:00        0.0        0.0        0.0        0.0        0.0   \n",
       "...                        ...        ...        ...        ...        ...   \n",
       "2021-10-11 05:00:00        0.0        0.0        0.0        0.0        0.0   \n",
       "2021-10-11 05:15:00        0.0        0.0        0.0        0.0        0.0   \n",
       "2021-10-11 05:30:00        0.0        0.0        0.0        0.0        0.0   \n",
       "2021-10-11 05:45:00        0.0        0.0        0.0        0.0        0.0   \n",
       "2021-10-11 06:00:00        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "                     month_9.0  month_10.0  month_11.0  month_12.0  \n",
       "datetime_local                                                      \n",
       "2018-12-31 21:15:00        0.0         0.0         0.0         1.0  \n",
       "2018-12-31 21:30:00        0.0         0.0         0.0         1.0  \n",
       "2018-12-31 21:45:00        0.0         0.0         0.0         1.0  \n",
       "2018-12-31 22:00:00        0.0         0.0         0.0         1.0  \n",
       "2018-12-31 22:15:00        0.0         0.0         0.0         1.0  \n",
       "...                        ...         ...         ...         ...  \n",
       "2021-10-11 05:00:00        0.0         1.0         0.0         0.0  \n",
       "2021-10-11 05:15:00        0.0         1.0         0.0         0.0  \n",
       "2021-10-11 05:30:00        0.0         1.0         0.0         0.0  \n",
       "2021-10-11 05:45:00        0.0         1.0         0.0         0.0  \n",
       "2021-10-11 06:00:00        0.0         1.0         0.0         0.0  \n",
       "\n",
       "[97380 rows x 34 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.resample('15min').last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
