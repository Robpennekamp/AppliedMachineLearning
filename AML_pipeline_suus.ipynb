{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6GgydedI6kRr",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math, datetime, time, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "\n",
    "def load_data(data_path):\n",
    "  data = pd.read_csv(data_path)  \n",
    "  return data\n",
    "\n",
    "inbound = load_data(\"inbound_loads.csv\")\n",
    "outbound = load_data(\"outbound_laods.csv\")\n",
    "weather = load_data(\"weather.csv\")\n",
    "door = load_data(\"feature_inbound_outbound_door_open.csv\")\n",
    "\n",
    "#For loop to ensure that all pallet data is in the same dataframe\n",
    "pallet = load_data(\"Pallet_history_Gold_Spike[0].csv\")\n",
    "for x in range(1, 10):\n",
    "    pallet = pd.concat([pallet, load_data(f\"Pallet_history_Gold_Spike[{x}].csv\")])\n",
    "trainentest = load_data(\"demand_kWtrain_val.csv\")\n",
    "train = trainentest.iloc[:273988,:]\n",
    "test = trainentest.iloc[273988:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan de campagne:\n",
    "\n",
    "- Process the weather data into workable data for the algo\n",
    "- Calculate on a minute-to-minute basis how many products are 'new' in the warehouse.\n",
    "- Try to process the inbound and outbound data to make the amounts of incoming and outgoing products available\n",
    "- Try to estimate on a minute-to-minute basis how many doors are open at any point in time.\n",
    "    - This should be done on a percentage-based scale (how much percent of the minute was a door open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pwIsOHLEjdRk"
   },
   "outputs": [],
   "source": [
    "# for data visualization\n",
    "import math, datetime, time, random\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatting door open from inbound and outbound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#door_outbound = door_outbound.rename(columns={\"counts\":\"count\"})\n",
    "#base_door = pd.concat([door_inbound, door_outbound['count']], axis=1)\n",
    "#base_door.set_index('datetime_local', inplace=True)\n",
    "#total = base_door['counts'] + base_door['count']  \n",
    "#base_door = base_door.assign(total=total)\n",
    "#base_door = base_door.drop(['counts', 'count'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_door = base_door.reset_index(level=[0])\n",
    "#base_door['datetime_local'] = pd.to_datetime(base_door['datetime_local'])\n",
    "#base_door['datetime_local'] = pd.Series(test.datetime_local.dt.to_pydatetime(), dtype='O')\n",
    "#type(base_door['datetime_local'][0])\n",
    "#type(base_door.datetime_local.iloc[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>demand_kW</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>weekday</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>datetime</th>\n",
       "      <th>Relative Humidity</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>datetime_UTC</th>\n",
       "      <th>hour</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime_local</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-12-31 18:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-12-31 18:00:00-06:00</td>\n",
       "      <td>50.37</td>\n",
       "      <td>53.6</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 18:05:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-12-31 18:05:00-06:00</td>\n",
       "      <td>50.37</td>\n",
       "      <td>53.6</td>\n",
       "      <td>2019-01-01 00:05:00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 18:10:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-12-31 18:10:00-06:00</td>\n",
       "      <td>50.37</td>\n",
       "      <td>53.6</td>\n",
       "      <td>2019-01-01 00:10:00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 18:15:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-12-31 18:15:00-06:00</td>\n",
       "      <td>50.37</td>\n",
       "      <td>53.6</td>\n",
       "      <td>2019-01-01 00:15:00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 18:20:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018-12-31 18:20:00-06:00</td>\n",
       "      <td>50.37</td>\n",
       "      <td>53.6</td>\n",
       "      <td>2019-01-01 00:20:00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-04 03:53:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-04 03:54:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-04 03:55:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-04 03:56:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-04 03:57:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1583005 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     demand_kW  year  month  weekday  day  hour  minute  \\\n",
       "datetime_local                                                            \n",
       "2018-12-31 18:00:00        NaN   NaN    NaN      NaN  NaN   NaN     NaN   \n",
       "2018-12-31 18:05:00        NaN   NaN    NaN      NaN  NaN   NaN     NaN   \n",
       "2018-12-31 18:10:00        NaN   NaN    NaN      NaN  NaN   NaN     NaN   \n",
       "2018-12-31 18:15:00        NaN   NaN    NaN      NaN  NaN   NaN     NaN   \n",
       "2018-12-31 18:20:00        NaN   NaN    NaN      NaN  NaN   NaN     NaN   \n",
       "...                        ...   ...    ...      ...  ...   ...     ...   \n",
       "2022-01-04 03:53:00        NaN   NaN    NaN      NaN  NaN   NaN     NaN   \n",
       "2022-01-04 03:54:00        NaN   NaN    NaN      NaN  NaN   NaN     NaN   \n",
       "2022-01-04 03:55:00        NaN   NaN    NaN      NaN  NaN   NaN     NaN   \n",
       "2022-01-04 03:56:00        NaN   NaN    NaN      NaN  NaN   NaN     NaN   \n",
       "2022-01-04 03:57:00        NaN   NaN    NaN      NaN  NaN   NaN     NaN   \n",
       "\n",
       "                                      datetime  Relative Humidity  \\\n",
       "datetime_local                                                      \n",
       "2018-12-31 18:00:00  2018-12-31 18:00:00-06:00              50.37   \n",
       "2018-12-31 18:05:00  2018-12-31 18:05:00-06:00              50.37   \n",
       "2018-12-31 18:10:00  2018-12-31 18:10:00-06:00              50.37   \n",
       "2018-12-31 18:15:00  2018-12-31 18:15:00-06:00              50.37   \n",
       "2018-12-31 18:20:00  2018-12-31 18:20:00-06:00              50.37   \n",
       "...                                        ...                ...   \n",
       "2022-01-04 03:53:00                        NaN                NaN   \n",
       "2022-01-04 03:54:00                        NaN                NaN   \n",
       "2022-01-04 03:55:00                        NaN                NaN   \n",
       "2022-01-04 03:56:00                        NaN                NaN   \n",
       "2022-01-04 03:57:00                        NaN                NaN   \n",
       "\n",
       "                     Temperature         datetime_UTC  hour  total  \n",
       "datetime_local                                                      \n",
       "2018-12-31 18:00:00         53.6  2019-01-01 00:00:00  18.0    NaN  \n",
       "2018-12-31 18:05:00         53.6  2019-01-01 00:05:00  18.0    NaN  \n",
       "2018-12-31 18:10:00         53.6  2019-01-01 00:10:00  18.0    NaN  \n",
       "2018-12-31 18:15:00         53.6  2019-01-01 00:15:00  18.0    NaN  \n",
       "2018-12-31 18:20:00         53.6  2019-01-01 00:20:00  18.0    NaN  \n",
       "...                          ...                  ...   ...    ...  \n",
       "2022-01-04 03:53:00          NaN                  NaN   NaN    3.0  \n",
       "2022-01-04 03:54:00          NaN                  NaN   NaN    3.0  \n",
       "2022-01-04 03:55:00          NaN                  NaN   NaN    3.0  \n",
       "2022-01-04 03:56:00          NaN                  NaN   NaN    2.0  \n",
       "2022-01-04 03:57:00          NaN                  NaN   NaN    2.0  \n",
       "\n",
       "[1583005 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def addtimecol(df, colname): ####input df and colname \n",
    "    df[colname] = pd.to_datetime(df[colname])         \n",
    "    df['year'] = df[colname].dt.year\n",
    "    df['month'] = df[colname].dt.month\n",
    "    df['weekday'] = df[colname].dt.weekday\n",
    "    df['day'] = df[colname].dt.day\n",
    "    df['hour'] = df[colname].dt.hour\n",
    "    df['minute'] = df[colname].dt.minute        \n",
    "    return df\n",
    "\n",
    "#Create new dummy dfs\n",
    "base_df = train.copy()\n",
    "base_weather = weather.copy()\n",
    "base_door = door.copy()\n",
    "#base_outbound_door = door_outbound.copy()\n",
    "\n",
    "#Remove unnecessary columns\n",
    "base_df = base_df.drop('Unnamed: 0', axis=1)\n",
    "base_weather = base_weather.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n",
    "base_weather[\"localstrptime\"]= pd.to_datetime(base_weather[\"localstrptime\"])\n",
    "base_df['datetime_local'] = pd.to_datetime(base_df['datetime_local'])\n",
    "base_door['datetime_local'] = pd.to_datetime(base_door['datetime_local'])\n",
    "base_weather = base_weather.rename(columns={'localstrptime':'datetime_local'})\n",
    "#base_weather['datetime_local'] = [datetime.datetime.strptime(x, 'yyyy/MM/dd HH:mm:SS') for x in base_weather['localstrptime']]\n",
    "\n",
    "#Add time columns.\n",
    "addtimecol(base_df, 'datetime_local')\n",
    "\n",
    "#Set index to datetime\n",
    "base_df.set_index('datetime_local', inplace=True)\n",
    "base_weather.set_index('datetime_local', inplace=True)\n",
    "base_door.set_index('datetime_local', inplace=True)\n",
    "\n",
    "#Concatenate the weather DataFrame to the base DataFrame\n",
    "base_df = pd.concat([base_df, base_weather], axis=1)\n",
    "base_df = pd.concat([base_df, base_door], axis=1)\n",
    "\n",
    "\n",
    "# Drop all NaN values\\n\"\n",
    "base_df.dropna(subset=['demand_kW', 'Temperature'])\n",
    "\n",
    "base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_door = base_door.reset_index(level=[0])\n",
    "base_door['datetime_local'] = pd.to_datetime(base_door['datetime_local'])\n",
    "#base_door['datetime_local'] = pd.Series(test.datetime_local.dt.to_pydatetime(), dtype='O')\n",
    "#type(base_door['datetime_local'][0])\n",
    "type(base_door.datetime_local.iloc[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df = base_df.dropna(subset=['demand_kW', 'Temperature', 'Relative Humidity'])\n",
    "dummy_df = dummy_df.reset_index()\n",
    "dummy_df = dummy_df.drop(['hour'], axis=1)\n",
    "dummy_df = dummy_df.drop(['datetime'], axis=1)\n",
    "dummy_df = dummy_df.drop(['datetime_local'], axis=1)\n",
    "dummy_df = dummy_df.drop(['datetime_UTC'], axis=1)\n",
    "dummy_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df.to_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "\n",
    "First we build the skeleton:\n",
    "- Divide into train/test\n",
    "- Set target column\n",
    "- Get Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "#Define train, test sets\\n\",\n",
    "train, test = train_test_split(dummy_df)\n",
    "X_train = train.copy().drop(['demand_kW'], axis=1)\n",
    "Y_train = train['demand_kW']\n",
    "X_test = test.copy().drop(['demand_kW'], axis=1)\n",
    "Y_test = test['demand_kW']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVR()\n",
    "svm.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = svm.predict(X_test)\n",
    "result = r2_score(list(Y_test), acc)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_svr = mean_squared_error(list(Y_test), acc)\n",
    "mae_svr = mean_absolute_error(list(Y_test), acc)\n",
    "\n",
    "print(\"mse\", mse_svr)\n",
    "print(\"mae\", mae_svr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators = 200)\n",
    "rf.fit(X_train, Y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_rf = rf.predict(X_test)\n",
    "\n",
    "result = r2_score(list(Y_test), acc_rf)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest - 100 trees = 0.9464962000675328\n",
    "Random Forest - 200 trees = 0.9471820046457805\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(list(Y_test), acc_rf)\n",
    "mae = mean_absolute_error(list(Y_test), acc_rf)\n",
    "\n",
    "print(\"mse\", mse)\n",
    "print(\"mae\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(Y_test))\n",
    "plt.plot(acc_rf)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = abs(list(Y_test) - acc_rf)\n",
    "diff\n",
    "\n",
    "y_axis = range(0,len(Y_test))\n",
    "y_axis\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "plt.scatter(y_axis,diff)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "plt.scatter(y_axis,Y_test)\n",
    "plt.scatter(y_axis,acc_rf)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
